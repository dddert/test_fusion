{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fusion 2026 — quality-first notebook (v2)\n",
    "\n",
    "Цель: поднять `macro ROC-AUC` выше базового `0.845` за счёт более устойчивого ансамбля:\n",
    "- `CatBoost MultiClassOneVsAll` (ловит межтаргетные зависимости);\n",
    "- `CatBoost OvR` по каждому таргету (лучше для редких классов);\n",
    "- тюнинг blend-весов по holdout в пространстве рангов;\n",
    "- дополнительный patch для худших таргетов с отдельными гиперпараметрами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# ======================\n",
    "# CONFIG\n",
    "# ======================\n",
    "DATA_DIR_CANDIDATES = [\n",
    "    Path('/kaggle/input/data-fusion-contest-2026'),\n",
    "    Path('/workspace/test_fusion'),\n",
    "]\n",
    "OUT_DIR = Path('./artifacts_v2')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# holdout only for model selection / blend tuning\n",
    "HOLDOUT_SIZE = 0.05\n",
    "SPLIT_SEED = 42\n",
    "\n",
    "# multi model\n",
    "MULTI_SEEDS = [42, 2026]\n",
    "MULTI_MAX_ITERS = 10000\n",
    "MULTI_OD_WAIT = 400\n",
    "\n",
    "# ovr model\n",
    "OVR_SEEDS = [42]\n",
    "OVR_MAX_ITERS = 7000\n",
    "OVR_OD_WAIT = 350\n",
    "\n",
    "# patching\n",
    "PATCH_TOP_K = 14\n",
    "PATCH_SEEDS = [3407, 7777]\n",
    "PATCH_GAIN_MIN = 0.0005\n",
    "\n",
    "# feature cleaning\n",
    "MISSING_RATE_DROP = 0.998\n",
    "NEAR_CONST_DROP = 0.9997\n",
    "\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    for p in DATA_DIR_CANDIDATES:\n",
    "        if (p / 'train_main_features.parquet').exists() and (p / 'train_target.parquet').exists():\n",
    "            return p\n",
    "    raise FileNotFoundError('Cannot locate dataset directory')\n",
    "\n",
    "\n",
    "def safe_auc(y_true: np.ndarray, y_score: np.ndarray) -> float:\n",
    "    if np.unique(y_true).size < 2:\n",
    "        return 0.5\n",
    "    return float(roc_auc_score(y_true, y_score))\n",
    "\n",
    "\n",
    "def rank_pct_1d(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(x)\n",
    "    n = x.shape[0]\n",
    "    order = np.argsort(x, kind='mergesort')\n",
    "    ranks = np.empty(n, dtype=np.int32)\n",
    "    ranks[order] = np.arange(n, dtype=np.int32)\n",
    "    return ((ranks + 1) / (n + 1)).astype(np.float32)\n",
    "\n",
    "\n",
    "def logit_from_rank(r: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    r = np.clip(r, eps, 1 - eps)\n",
    "    return np.log(r / (1 - r)).astype(np.float32)\n",
    "\n",
    "\n",
    "def macro_auc(y_true: np.ndarray, y_score: np.ndarray) -> float:\n",
    "    per_target = [safe_auc(y_true[:, j], y_score[:, j]) for j in range(y_true.shape[1])]\n",
    "    return float(np.mean(per_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# DATA + FEATURES\n",
    "# ======================\n",
    "DATA_DIR = find_data_dir()\n",
    "print('DATA_DIR =', DATA_DIR)\n",
    "\n",
    "train_main = pd.read_parquet(DATA_DIR / 'train_main_features.parquet')\n",
    "train_extra = pd.read_parquet(DATA_DIR / 'train_extra_features.parquet')\n",
    "test_main = pd.read_parquet(DATA_DIR / 'test_main_features.parquet')\n",
    "test_extra = pd.read_parquet(DATA_DIR / 'test_extra_features.parquet')\n",
    "train_target = pd.read_parquet(DATA_DIR / 'train_target.parquet')\n",
    "sample_submit = pd.read_parquet(DATA_DIR / 'sample_submit.parquet')\n",
    "\n",
    "train_df = train_main.merge(train_extra, on='customer_id', how='left', suffixes=('', '_extra'))\n",
    "test_df = test_main.merge(test_extra, on='customer_id', how='left', suffixes=('', '_extra'))\n",
    "\n",
    "id_col = 'customer_id'\n",
    "target_cols = [c for c in train_target.columns if c != id_col]\n",
    "\n",
    "full_train = train_df.merge(train_target, on=id_col, how='inner')\n",
    "\n",
    "feature_cols = [c for c in train_df.columns if c != id_col]\n",
    "cat_cols = [c for c in feature_cols if c.startswith('cat_feature_')]\n",
    "num_cols = [c for c in feature_cols if c.startswith('num_feature_')]\n",
    "\n",
    "# drop ultra-missing and near-constant columns\n",
    "missing_rate = full_train[feature_cols].isna().mean()\n",
    "keep_cols = [c for c in feature_cols if missing_rate[c] <= MISSING_RATE_DROP]\n",
    "\n",
    "final_keep = []\n",
    "for c in keep_cols:\n",
    "    vc = full_train[c].value_counts(dropna=False, normalize=True)\n",
    "    dom = float(vc.iloc[0]) if len(vc) > 0 else 1.0\n",
    "    if dom < NEAR_CONST_DROP:\n",
    "        final_keep.append(c)\n",
    "\n",
    "feature_cols = final_keep\n",
    "cat_cols = [c for c in cat_cols if c in feature_cols]\n",
    "cat_idx = [feature_cols.index(c) for c in cat_cols]\n",
    "\n",
    "X = full_train[feature_cols].copy()\n",
    "X_test = test_df[feature_cols].copy()\n",
    "y = full_train[target_cols].values.astype(np.int32)\n",
    "\n",
    "# CatBoost требует cat_features как string/int (не float)\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype('string').fillna('__NaN__').astype(str)\n",
    "    X_test[c] = X_test[c].astype('string').fillna('__NaN__').astype(str)\n",
    "\n",
    "print('train shape:', X.shape, 'test shape:', X_test.shape)\n",
    "print('targets:', len(target_cols), 'cat feats:', len(cat_cols))\n",
    "\n",
    "# stratification proxy: count of active labels clipped\n",
    "strat = np.clip(y.sum(axis=1), 0, 5)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=HOLDOUT_SIZE, random_state=SPLIT_SEED)\n",
    "tr_idx, va_idx = next(sss.split(np.zeros(len(strat)), strat))\n",
    "\n",
    "X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "print('split:', X_tr.shape, X_va.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# MODEL 1: MULTI\n",
    "# ======================\n",
    "va_multi_probs = np.zeros((X_va.shape[0], y.shape[1]), dtype=np.float32)\n",
    "test_multi_probs = np.zeros((X_test.shape[0], y.shape[1]), dtype=np.float32)\n",
    "best_iters_multi = []\n",
    "\n",
    "for seed in MULTI_SEEDS:\n",
    "    m = CatBoostClassifier(\n",
    "        loss_function='MultiClassOneVsAll',\n",
    "        eval_metric='MultiClass',\n",
    "        task_type='GPU',\n",
    "        devices='0',\n",
    "        iterations=MULTI_MAX_ITERS,\n",
    "        learning_rate=0.03,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=6.0,\n",
    "        random_strength=0.5,\n",
    "        bootstrap_type='Bernoulli',\n",
    "        subsample=0.9,\n",
    "        od_type='Iter',\n",
    "        od_wait=MULTI_OD_WAIT,\n",
    "        random_seed=seed,\n",
    "        verbose=200,\n",
    "        allow_writing_files=False,\n",
    "    )\n",
    "    m.fit(Pool(X_tr, y_tr, cat_features=cat_idx), eval_set=Pool(X_va, y_va, cat_features=cat_idx), use_best_model=True)\n",
    "    best_it = int(m.get_best_iteration()) if m.get_best_iteration() is not None else MULTI_MAX_ITERS\n",
    "    best_iters_multi.append(best_it)\n",
    "\n",
    "    va_multi_probs += m.predict_proba(Pool(X_va, cat_features=cat_idx)) / len(MULTI_SEEDS)\n",
    "\n",
    "    m_full = CatBoostClassifier(\n",
    "        **{k: v for k, v in m.get_params().items() if k not in ['iterations', 'od_wait']},\n",
    "        iterations=max(best_it, 200),\n",
    "        od_wait=None,\n",
    "    )\n",
    "    m_full.fit(Pool(X, y, cat_features=cat_idx), verbose=0)\n",
    "    test_multi_probs += m_full.predict_proba(Pool(X_test, cat_features=cat_idx)) / len(MULTI_SEEDS)\n",
    "\n",
    "print('mean best_iter multi =', np.mean(best_iters_multi))\n",
    "print('holdout macro AUC multi =', macro_auc(y_va, va_multi_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# MODEL 2: OVR\n",
    "# ======================\n",
    "va_ovr_probs = np.zeros((X_va.shape[0], y.shape[1]), dtype=np.float32)\n",
    "test_ovr_probs = np.zeros((X_test.shape[0], y.shape[1]), dtype=np.float32)\n",
    "per_target_auc = []\n",
    "\n",
    "for t_idx, t in enumerate(target_cols):\n",
    "    y_tr_t = y_tr[:, t_idx]\n",
    "    y_va_t = y_va[:, t_idx]\n",
    "    pos_rate = float(y_tr_t.mean())\n",
    "\n",
    "    if pos_rate < 0.003:\n",
    "        depth, lr, l2 = 10, 0.025, 10.0\n",
    "    elif pos_rate < 0.02:\n",
    "        depth, lr, l2 = 9, 0.03, 8.0\n",
    "    else:\n",
    "        depth, lr, l2 = 8, 0.035, 6.0\n",
    "\n",
    "    spw = float((1 - pos_rate) / max(pos_rate, 1e-6))\n",
    "    spw = float(np.clip(spw, 1.0, 150.0))\n",
    "\n",
    "    va_pred_seed = np.zeros(X_va.shape[0], dtype=np.float32)\n",
    "    test_pred_seed = np.zeros(X_test.shape[0], dtype=np.float32)\n",
    "    best_its = []\n",
    "\n",
    "    for seed in OVR_SEEDS:\n",
    "        clf = CatBoostClassifier(\n",
    "            loss_function='Logloss',\n",
    "            eval_metric='Logloss',\n",
    "            task_type='GPU',\n",
    "            devices='0',\n",
    "            iterations=OVR_MAX_ITERS,\n",
    "            learning_rate=lr,\n",
    "            depth=depth,\n",
    "            l2_leaf_reg=l2,\n",
    "            bootstrap_type='Bernoulli',\n",
    "            subsample=0.9,\n",
    "            od_type='Iter',\n",
    "            od_wait=OVR_OD_WAIT,\n",
    "            random_seed=seed,\n",
    "            scale_pos_weight=spw,\n",
    "            verbose=0,\n",
    "            allow_writing_files=False,\n",
    "        )\n",
    "        clf.fit(Pool(X_tr, y_tr_t, cat_features=cat_idx), eval_set=Pool(X_va, y_va_t, cat_features=cat_idx), use_best_model=True)\n",
    "        bi = int(clf.get_best_iteration()) if clf.get_best_iteration() is not None else OVR_MAX_ITERS\n",
    "        best_its.append(max(bi, 150))\n",
    "\n",
    "        va_pred_seed += clf.predict_proba(Pool(X_va, cat_features=cat_idx))[:, 1] / len(OVR_SEEDS)\n",
    "\n",
    "        clf_full = CatBoostClassifier(\n",
    "            **{k: v for k, v in clf.get_params().items() if k not in ['iterations', 'od_wait']},\n",
    "            iterations=max(bi, 150),\n",
    "            od_wait=None,\n",
    "        )\n",
    "        clf_full.fit(Pool(X, y[:, t_idx], cat_features=cat_idx), verbose=0)\n",
    "        test_pred_seed += clf_full.predict_proba(Pool(X_test, cat_features=cat_idx))[:, 1] / len(OVR_SEEDS)\n",
    "\n",
    "    va_ovr_probs[:, t_idx] = va_pred_seed\n",
    "    test_ovr_probs[:, t_idx] = test_pred_seed\n",
    "    per_target_auc.append((t, safe_auc(y_va_t, va_pred_seed), pos_rate, int(np.mean(best_its))))\n",
    "\n",
    "auc_df = pd.DataFrame(per_target_auc, columns=['target', 'auc_ovr_holdout', 'pos_rate', 'best_iter'])\n",
    "auc_df = auc_df.sort_values('auc_ovr_holdout')\n",
    "auc_df.to_csv(OUT_DIR / 'per_target_auc_ovr.csv', index=False)\n",
    "\n",
    "print('holdout macro AUC ovr =', macro_auc(y_va, va_ovr_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# BLENDING + PATCHING\n",
    "# ======================\n",
    "# blend in rank space, target-wise\n",
    "va_final = np.zeros_like(va_ovr_probs)\n",
    "test_final = np.zeros_like(test_ovr_probs)\n",
    "blend_rows = []\n",
    "\n",
    "for j, t in enumerate(target_cols):\n",
    "    yj = y_va[:, j]\n",
    "    r_multi = rank_pct_1d(va_multi_probs[:, j])\n",
    "    r_ovr = rank_pct_1d(va_ovr_probs[:, j])\n",
    "\n",
    "    best_auc = -1.0\n",
    "    best_w = 0.5\n",
    "    for w in np.linspace(0.0, 1.0, 21):\n",
    "        r = (1 - w) * r_multi + w * r_ovr\n",
    "        auc = safe_auc(yj, r)\n",
    "        if auc > best_auc:\n",
    "            best_auc, best_w = auc, float(w)\n",
    "\n",
    "    blend_rows.append((t, best_w, best_auc))\n",
    "\n",
    "    va_final[:, j] = (1 - best_w) * r_multi + best_w * r_ovr\n",
    "\n",
    "    rt_multi = rank_pct_1d(test_multi_probs[:, j])\n",
    "    rt_ovr = rank_pct_1d(test_ovr_probs[:, j])\n",
    "    rt = (1 - best_w) * rt_multi + best_w * rt_ovr\n",
    "    test_final[:, j] = 1 / (1 + np.exp(-logit_from_rank(rt)))\n",
    "\n",
    "blend_df = pd.DataFrame(blend_rows, columns=['target', 'w_ovr', 'auc_holdout'])\n",
    "blend_df.to_csv(OUT_DIR / 'blend_weights.csv', index=False)\n",
    "\n",
    "print('holdout macro AUC blended =', macro_auc(y_va, va_final))\n",
    "\n",
    "# optional patch for worst targets\n",
    "worst_targets = blend_df.sort_values('auc_holdout').head(PATCH_TOP_K)['target'].tolist()\n",
    "print('patch targets:', worst_targets)\n",
    "\n",
    "patch_log = []\n",
    "for t in worst_targets:\n",
    "    j = target_cols.index(t)\n",
    "    y_tr_t, y_va_t = y_tr[:, j], y_va[:, j]\n",
    "    base_auc = safe_auc(y_va_t, va_final[:, j])\n",
    "\n",
    "    # slightly more aggressive model for hard targets\n",
    "    pos_rate = float(y_tr_t.mean())\n",
    "    spw = float(np.clip((1 - pos_rate) / max(pos_rate, 1e-6), 1.0, 200.0))\n",
    "\n",
    "    va_patch = np.zeros(X_va.shape[0], dtype=np.float32)\n",
    "    te_patch = np.zeros(X_test.shape[0], dtype=np.float32)\n",
    "\n",
    "    for seed in PATCH_SEEDS:\n",
    "        patch = CatBoostClassifier(\n",
    "            loss_function='Logloss', eval_metric='Logloss',\n",
    "            task_type='GPU', devices='0',\n",
    "            iterations=9000, learning_rate=0.022,\n",
    "            depth=10, l2_leaf_reg=12.0,\n",
    "            random_strength=1.2,\n",
    "            bootstrap_type='Bernoulli', subsample=0.85,\n",
    "            od_type='Iter', od_wait=450,\n",
    "            scale_pos_weight=spw,\n",
    "            random_seed=seed, verbose=0,\n",
    "            allow_writing_files=False,\n",
    "        )\n",
    "        patch.fit(Pool(X_tr, y_tr_t, cat_features=cat_idx), eval_set=Pool(X_va, y_va_t, cat_features=cat_idx), use_best_model=True)\n",
    "        bi = int(patch.get_best_iteration()) if patch.get_best_iteration() is not None else 4000\n",
    "\n",
    "        va_patch += patch.predict_proba(Pool(X_va, cat_features=cat_idx))[:, 1] / len(PATCH_SEEDS)\n",
    "\n",
    "        patch_full = CatBoostClassifier(\n",
    "            **{k: v for k, v in patch.get_params().items() if k not in ['iterations', 'od_wait']},\n",
    "            iterations=max(bi, 200), od_wait=None,\n",
    "        )\n",
    "        patch_full.fit(Pool(X, y[:, j], cat_features=cat_idx), verbose=0)\n",
    "        te_patch += patch_full.predict_proba(Pool(X_test, cat_features=cat_idx))[:, 1] / len(PATCH_SEEDS)\n",
    "\n",
    "    # rank blend base + patch\n",
    "    rb = rank_pct_1d(va_final[:, j])\n",
    "    rp = rank_pct_1d(va_patch)\n",
    "    best_auc = base_auc\n",
    "    best_w = 0.0\n",
    "    for w in [0.0, 0.15, 0.30, 0.45, 0.60]:\n",
    "        auc = safe_auc(y_va_t, (1 - w) * rb + w * rp)\n",
    "        if auc > best_auc:\n",
    "            best_auc, best_w = auc, w\n",
    "\n",
    "    if best_auc >= base_auc + PATCH_GAIN_MIN:\n",
    "        va_final[:, j] = (1 - best_w) * rb + best_w * rp\n",
    "\n",
    "        rtb = rank_pct_1d(test_final[:, j])\n",
    "        rtp = rank_pct_1d(te_patch)\n",
    "        rt = (1 - best_w) * rtb + best_w * rtp\n",
    "        test_final[:, j] = 1 / (1 + np.exp(-logit_from_rank(rt)))\n",
    "\n",
    "    patch_log.append((t, base_auc, best_auc, best_w))\n",
    "\n",
    "patch_df = pd.DataFrame(patch_log, columns=['target', 'base_auc', 'patched_auc', 'patch_w'])\n",
    "patch_df.to_csv(OUT_DIR / 'patch_report.csv', index=False)\n",
    "\n",
    "print('holdout macro AUC final =', macro_auc(y_va, va_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# SAVE SUBMISSION\n",
    "# ======================\n",
    "submission = sample_submit[[id_col]].copy()\n",
    "for j, t in enumerate(target_cols):\n",
    "    # submit as logit-like margins (common robust format for this comp)\n",
    "    p = np.clip(test_final[:, j], 1e-6, 1 - 1e-6)\n",
    "    submission[t] = np.log(p / (1 - p)).astype(np.float32)\n",
    "\n",
    "sub_path = OUT_DIR / 'submission_v2.parquet'\n",
    "submission.to_parquet(sub_path, index=False)\n",
    "\n",
    "meta = {\n",
    "    'data_dir': str(DATA_DIR),\n",
    "    'n_features': int(len(feature_cols)),\n",
    "    'n_cat_features': int(len(cat_cols)),\n",
    "    'holdout_macro_auc_final': float(macro_auc(y_va, va_final)),\n",
    "}\n",
    "with open(OUT_DIR / 'run_meta.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print('Saved:', sub_path)\n",
    "print(json.dumps(meta, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}