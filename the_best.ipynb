{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaH100",
   "dataSources": [
    {
     "sourceType": "competition",
     "sourceId": 118448,
     "databundleVersionId": 14559231
    },
    {
     "sourceType": "datasetVersion",
     "sourceId": 14830322,
     "datasetId": 9484844,
     "databundleVersionId": 15688136
    }
   ],
   "dockerImageVersionId": 31260,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "8597f546",
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Data Fusion Contest 2026 Task 2: quality-first training pipeline + EDA (FULL-TRAIN + BEST_ITER).\n",
    "\n",
    "Fixes vs previous FULL-TRAIN block:\n",
    "1) Best iteration is now selected correctly:\n",
    "   - We train on (train_split) with eval_set=(holdout) + early stopping\n",
    "   - Read model.get_best_iteration()  (best on holdout metric)\n",
    "   - Retrain on FULL TRAIN with iterations = best_iter (no eval_set)\n",
    "2) Blend weights are tuned on holdout (global or per-target), then applied to FULL-TRAIN test preds.\n",
    "3) Feature hygiene stats are corrected (no confusing counts).\n",
    "4) Safer merging by customer_id (instead of assuming row order).\n",
    "\n",
    "Outputs:\n",
    "- submission.parquet (raw margins/logits; schema matches sample)\n",
    "- eda_report.md\n",
    "- blend_weights.csv (if per-target tuning enabled)\n",
    "- best_iters.csv (best iterations for Multi + OvR per target)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CONFIG (edit on Kaggle)\n",
    "# =========================\n",
    "DATA_DIR = Path(\"/kaggle/input/data-fusion-contest-2026\")\n",
    "OUTPUT_PATH = Path(\"submission.parquet\")\n",
    "EDA_REPORT_PATH = Path(\"eda_report.md\")\n",
    "BLEND_WEIGHTS_REPORT_PATH = Path(\"blend_weights.csv\")\n",
    "BEST_ITERS_REPORT_PATH = Path(\"best_iters.csv\")\n",
    "\n",
    "# If DATA_DIR does not exist, try kagglehub download.\n",
    "USE_KAGGLEHUB_DOWNLOAD = False\n",
    "KAGGLE_DATASET_ID = \"hatab123/data-fusion-contest-2026\"\n",
    "\n",
    "# FULL TRAIN seeds\n",
    "MULTI_SEEDS = [42]\n",
    "OVR_SEEDS = [2026]\n",
    "\n",
    "# Holdout used ONLY for:\n",
    "# - early stopping (best iteration selection)\n",
    "# - blend weight tuning\n",
    "TUNE_HOLDOUT_SIZE = 0.05\n",
    "TUNE_SEED = 42\n",
    "\n",
    "# Blend options (public-LB robust mode)\n",
    "AUTO_TUNE_BLEND_WEIGHT = True\n",
    "USE_PER_TARGET_BLEND = True  # recommended for macro AUC\n",
    "APPLY_RANK_BLEND = True      # blend on rank-normalized probs for robustness\n",
    "MIN_HOLDOUT_GAIN_FOR_OVR = 0.0008\n",
    "BLEND_GRID = np.array([0.60, 0.75, 0.85, 0.92, 1.00], dtype=np.float64)\n",
    "MIN_MULTI_WEIGHT = 0.75      # shrink per-target weights toward Multi backbone\n",
    "DEFAULT_BLEND_WEIGHT_MULTI = 0.90\n",
    "\n",
    "# Optional targeted patch stage (for worst holdout targets)\n",
    "ENABLE_PATCH_STAGE = True\n",
    "PATCH_TOP_K = 20\n",
    "PATCH_SEEDS = [42, 1337]\n",
    "PATCH_MIN_GAIN = 0.0008\n",
    "PATCH_BLEND_GRID = np.array([0.0, 0.15, 0.30, 0.45], dtype=np.float64)\n",
    "PATCH_VAL_SHARE = 0.05\n",
    "PATCH_MAX_ITERS = 2200\n",
    "PATCH_OD_WAIT = 180\n",
    "\n",
    "# Feature hygiene\n",
    "DROP_CONST_FEATURES = True\n",
    "DROP_NEAR_CONST_FEATURES = True\n",
    "NEAR_CONST_DOMINANCE_THRESHOLD = 0.9995\n",
    "MISSING_RATE_THRESHOLD = 0.997  # drop columns with >99.7% missing\n",
    "\n",
    "# Training caps (upper bounds; early stopping will usually stop earlier)\n",
    "MULTI_MAX_ITERS = 10000\n",
    "MULTI_OD_WAIT = 350\n",
    "\n",
    "OVR_MAX_ITERS = 6000\n",
    "OVR_OD_WAIT = 300\n",
    "\n",
    "# For binary on GPU, use Logloss for early stopping (AUC isn't properly supported on GPU)\n",
    "OVR_EVAL_METRIC = \"Logloss\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "def logit(p: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    p = np.clip(p, eps, 1.0 - eps)\n",
    "    return np.log(p / (1.0 - p))\n",
    "\n",
    "\n",
    "def safe_auc(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    if np.unique(y_true).shape[0] < 2:\n",
    "        return 0.5\n",
    "    return float(roc_auc_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "def rank_normalize_2d(arr: np.ndarray) -> np.ndarray:\n",
    "    out = np.zeros_like(arr, dtype=np.float64)\n",
    "    n = arr.shape[0]\n",
    "    if n <= 1:\n",
    "        return np.full_like(arr, 0.5, dtype=np.float64)\n",
    "\n",
    "    for j in range(arr.shape[1]):\n",
    "        order = np.argsort(arr[:, j], kind=\"mergesort\")\n",
    "        ranks = np.empty(n, dtype=np.float64)\n",
    "        ranks[order] = np.arange(n, dtype=np.float64)\n",
    "        out[:, j] = ranks / (n - 1.0)\n",
    "\n",
    "    eps = 1e-6\n",
    "    return np.clip(out, eps, 1.0 - eps)\n",
    "\n",
    "\n",
    "def resolve_data_dir() -> Path:\n",
    "    if DATA_DIR.exists():\n",
    "        return DATA_DIR\n",
    "\n",
    "    if not USE_KAGGLEHUB_DOWNLOAD:\n",
    "        raise FileNotFoundError(\n",
    "            f\"DATA_DIR not found: {DATA_DIR}. Set correct path or enable USE_KAGGLEHUB_DOWNLOAD.\"\n",
    "        )\n",
    "\n",
    "    import kagglehub\n",
    "\n",
    "    downloaded_root = Path(kagglehub.dataset_download(KAGGLE_DATASET_ID))\n",
    "    print(f\"Downloaded dataset root: {downloaded_root}\")\n",
    "\n",
    "    if (downloaded_root / \"data\").exists():\n",
    "        return downloaded_root / \"data\"\n",
    "    return downloaded_root\n",
    "\n",
    "\n",
    "def load_data(data_dir: Path) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    train_main = pd.read_parquet(data_dir / \"train_main_features.parquet\")\n",
    "    train_extra = pd.read_parquet(data_dir / \"train_extra_features.parquet\")\n",
    "    test_main = pd.read_parquet(data_dir / \"test_main_features.parquet\")\n",
    "    test_extra = pd.read_parquet(data_dir / \"test_extra_features.parquet\")\n",
    "    target = pd.read_parquet(data_dir / \"train_target.parquet\")\n",
    "    sample_submit = pd.read_parquet(data_dir / \"sample_submit.parquet\")\n",
    "    return train_main, train_extra, test_main, test_extra, target, sample_submit\n",
    "\n",
    "\n",
    "def merge_features(main_df: pd.DataFrame, extra_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # safer: join by customer_id\n",
    "    if \"customer_id\" in main_df.columns and \"customer_id\" in extra_df.columns:\n",
    "        # drop duplicates if any\n",
    "        overlap = [c for c in extra_df.columns if c in main_df.columns and c != \"customer_id\"]\n",
    "        extra_use = extra_df.drop(columns=overlap) if overlap else extra_df\n",
    "        return main_df.merge(extra_use, on=\"customer_id\", how=\"left\")\n",
    "    # fallback: concat\n",
    "    cols_to_add = [c for c in extra_df.columns if c not in main_df.columns]\n",
    "    return pd.concat([main_df, extra_df[cols_to_add]], axis=1)\n",
    "\n",
    "\n",
    "def run_eda(train_full: pd.DataFrame, test_full: pd.DataFrame, target: pd.DataFrame, report_path: Path) -> None:\n",
    "    feature_cols = [c for c in train_full.columns if c != \"customer_id\"]\n",
    "    cat_cols = [c for c in feature_cols if c.startswith(\"cat_feature\")]\n",
    "    num_cols = [c for c in feature_cols if c.startswith(\"num_feature\")]\n",
    "\n",
    "    miss_train = train_full[feature_cols].isna().mean().sort_values(ascending=False)\n",
    "    miss_test = test_full[feature_cols].isna().mean().sort_values(ascending=False)\n",
    "\n",
    "    target_cols = [c for c in target.columns if c != \"customer_id\"]\n",
    "    pos_rate = target[target_cols].mean().sort_values(ascending=False)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"# EDA report\\n\")\n",
    "    lines.append(f\"- train_full shape: {train_full.shape}\")\n",
    "    lines.append(f\"- test_full shape: {test_full.shape}\")\n",
    "    lines.append(f\"- target shape: {target.shape}\")\n",
    "    lines.append(f\"- feature count: {len(feature_cols)}\")\n",
    "    lines.append(f\"- categorical features: {len(cat_cols)}\")\n",
    "    lines.append(f\"- numerical features: {len(num_cols)}\\n\")\n",
    "\n",
    "    lines.append(\"## Missingness\")\n",
    "    lines.append(f\"- mean missing rate (train): {miss_train.mean():.4f}\")\n",
    "    lines.append(f\"- mean missing rate (test): {miss_test.mean():.4f}\")\n",
    "    lines.append(\"- top-20 missing features (train):\")\n",
    "    for name, val in miss_train.head(20).items():\n",
    "        lines.append(f\"  - {name}: {val:.4f}\")\n",
    "\n",
    "    lines.append(\"\\n## Target prevalence\")\n",
    "    lines.append(f\"- mean positive rate across targets: {pos_rate.mean():.4f}\")\n",
    "    lines.append(\"- top-10 most frequent targets:\")\n",
    "    for name, val in pos_rate.head(10).items():\n",
    "        lines.append(f\"  - {name}: {val:.4f}\")\n",
    "    lines.append(\"- top-10 rarest targets:\")\n",
    "    for name, val in pos_rate.tail(10).items():\n",
    "        lines.append(f\"  - {name}: {val:.4f}\")\n",
    "\n",
    "    report_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    print(f\"EDA report saved to: {report_path}\")\n",
    "\n",
    "\n",
    "def apply_feature_hygiene(train_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, int]]:\n",
    "    feature_cols = [c for c in train_df.columns if c != \"customer_id\"]\n",
    "\n",
    "    const_set = set()\n",
    "    near_const_set = set()\n",
    "    ultra_missing_set = set()\n",
    "\n",
    "    if DROP_CONST_FEATURES:\n",
    "        const_set = {c for c in feature_cols if train_df[c].nunique(dropna=False) <= 1}\n",
    "\n",
    "    if DROP_NEAR_CONST_FEATURES:\n",
    "        for col in feature_cols:\n",
    "            vc = train_df[col].value_counts(dropna=False, normalize=True)\n",
    "            if len(vc) > 0 and float(vc.iloc[0]) >= NEAR_CONST_DOMINANCE_THRESHOLD:\n",
    "                near_const_set.add(col)\n",
    "\n",
    "    missing_rate = train_df[feature_cols].isna().mean()\n",
    "    ultra_missing_set = set(missing_rate[missing_rate > MISSING_RATE_THRESHOLD].index.tolist())\n",
    "\n",
    "    drop_cols = const_set | near_const_set | ultra_missing_set\n",
    "\n",
    "    keep_cols = [c for c in train_df.columns if c not in drop_cols]\n",
    "    train_df2 = train_df[keep_cols].copy()\n",
    "    test_df2 = test_df[keep_cols].copy()\n",
    "\n",
    "    stats = {\n",
    "        \"dropped_total_unique\": len(drop_cols),\n",
    "        \"dropped_const\": len(const_set),\n",
    "        \"dropped_near_const\": len(near_const_set),\n",
    "        \"dropped_ultra_missing\": len(ultra_missing_set),\n",
    "        \"overlap_nearconst_ultramissing\": len(near_const_set & ultra_missing_set),\n",
    "    }\n",
    "    print(f\"Feature hygiene stats: {stats}\")\n",
    "    return train_df2, test_df2, stats\n",
    "\n",
    "\n",
    "def preprocess_cats(train_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, List[int], List[str]]:\n",
    "    feature_cols = [c for c in train_df.columns if c != \"customer_id\"]\n",
    "    cat_cols = [c for c in feature_cols if c.startswith(\"cat_feature\")]\n",
    "\n",
    "    for col in cat_cols:\n",
    "        train_df[col] = train_df[col].fillna(\"__MISSING__\").astype(str)\n",
    "        test_df[col] = test_df[col].fillna(\"__MISSING__\").astype(str)\n",
    "\n",
    "    cat_indices = [feature_cols.index(c) for c in cat_cols]\n",
    "    return train_df, test_df, cat_indices, feature_cols\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Training helpers\n",
    "# =========================\n",
    "def _best_iter_from_model(model: CatBoostClassifier, fallback_iters: int) -> int:\n",
    "    bi = model.get_best_iteration()\n",
    "    if bi is None or bi < 0:\n",
    "        # tree_count_ is number of trees, best iteration unknown -> use all\n",
    "        return int(fallback_iters)\n",
    "    # get_best_iteration is 0-based; iterations parameter expects count\n",
    "    return int(bi) + 1\n",
    "\n",
    "\n",
    "def train_multilabel_tune_best_iter(\n",
    "    x_tr: pd.DataFrame,\n",
    "    y_tr: pd.DataFrame,\n",
    "    x_va: pd.DataFrame,\n",
    "    y_va: pd.DataFrame,\n",
    "    cat_indices: List[int],\n",
    "    seeds: List[int],\n",
    ") -> Tuple[int, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Train MultiLogloss on train-split with eval_set=holdout and early stopping.\n",
    "    Returns:\n",
    "      best_iter_multi (median across seeds)\n",
    "      pred_va_raw averaged across seeds (raw margins on holdout)\n",
    "    \"\"\"\n",
    "    n_targets = y_tr.shape[1]\n",
    "    pred_va = np.zeros((x_va.shape[0], n_targets), dtype=np.float64)\n",
    "    best_iters = []\n",
    "\n",
    "    tr_pool = Pool(x_tr, label=y_tr, cat_features=cat_indices)\n",
    "    va_pool = Pool(x_va, label=y_va, cat_features=cat_indices)\n",
    "\n",
    "    for i, seed in enumerate(seeds, start=1):\n",
    "        print(f\"[Multi-TUNE] seed={seed} ({i}/{len(seeds)})\")\n",
    "        model = CatBoostClassifier(\n",
    "            loss_function=\"MultiLogloss\",\n",
    "            eval_metric=\"MultiLogloss\",\n",
    "            iterations=MULTI_MAX_ITERS,\n",
    "            learning_rate=0.028,\n",
    "            depth=8,\n",
    "            l2_leaf_reg=9.0,\n",
    "            random_strength=1.2,\n",
    "            bagging_temperature=0.8,\n",
    "            border_count=254,\n",
    "            bootstrap_type=\"Bayesian\",\n",
    "            leaf_estimation_iterations=5,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=MULTI_OD_WAIT,\n",
    "            random_seed=seed,\n",
    "            task_type=\"GPU\",\n",
    "            devices=\"0\",\n",
    "            verbose=300,\n",
    "            allow_writing_files=False,\n",
    "        )\n",
    "        model.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n",
    "\n",
    "        bi = _best_iter_from_model(model, MULTI_MAX_ITERS)\n",
    "        best_iters.append(bi)\n",
    "        pred_va += model.predict(va_pool, prediction_type=\"RawFormulaVal\") / max(len(seeds), 1)\n",
    "\n",
    "    best_iter_multi = int(np.median(best_iters))\n",
    "    print(f\"[Multi-TUNE] best_iter candidates={best_iters} -> median={best_iter_multi}\")\n",
    "    return best_iter_multi, pred_va\n",
    "\n",
    "\n",
    "def train_multilabel_fulltrain(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_test: pd.DataFrame,\n",
    "    cat_indices: List[int],\n",
    "    seeds: List[int],\n",
    "    iterations: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Train MultiLogloss on FULL train with fixed iterations (best_iter from tuning).\n",
    "    Returns raw margins on test averaged across seeds.\n",
    "    \"\"\"\n",
    "    n_targets = y_train.shape[1]\n",
    "    test_pred = np.zeros((x_test.shape[0], n_targets), dtype=np.float64)\n",
    "\n",
    "    train_pool = Pool(x_train, label=y_train, cat_features=cat_indices)\n",
    "    test_pool = Pool(x_test, cat_features=cat_indices)\n",
    "\n",
    "    for i, seed in enumerate(seeds, start=1):\n",
    "        print(f\"[Multi-FULL] seed={seed} ({i}/{len(seeds)}) iters={iterations}\")\n",
    "        model = CatBoostClassifier(\n",
    "            loss_function=\"MultiLogloss\",\n",
    "            eval_metric=\"MultiLogloss\",\n",
    "            iterations=int(iterations),\n",
    "            learning_rate=0.028,\n",
    "            depth=8,\n",
    "            l2_leaf_reg=9.0,\n",
    "            random_strength=1.2,\n",
    "            bagging_temperature=0.8,\n",
    "            border_count=254,\n",
    "            bootstrap_type=\"Bayesian\",\n",
    "            leaf_estimation_iterations=5,\n",
    "            random_seed=seed,\n",
    "            task_type=\"GPU\",\n",
    "            devices=\"0\",\n",
    "            verbose=300,\n",
    "            allow_writing_files=False,\n",
    "        )\n",
    "        model.fit(train_pool)\n",
    "        test_pred += model.predict(test_pool, prediction_type=\"RawFormulaVal\") / max(len(seeds), 1)\n",
    "\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "def train_ovr_tune_best_iters(\n",
    "    x_tr: pd.DataFrame,\n",
    "    y_tr: pd.DataFrame,\n",
    "    x_va: pd.DataFrame,\n",
    "    y_va: pd.DataFrame,\n",
    "    cat_indices: List[int],\n",
    "    seeds: List[int],\n",
    "    target_names: List[str],\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Tune best iterations per target on train-split with eval_set=holdout and early stopping.\n",
    "    Returns:\n",
    "      best_iters_ovr: int array shape (n_targets,)\n",
    "      pred_va_raw: raw margins on holdout averaged across seeds (shape holdout x n_targets)\n",
    "    \"\"\"\n",
    "    n_targets = y_tr.shape[1]\n",
    "    best_iters = np.zeros(n_targets, dtype=np.int32)\n",
    "    pred_va = np.zeros((x_va.shape[0], n_targets), dtype=np.float64)\n",
    "\n",
    "    for j, tname in enumerate(target_names):\n",
    "        ytr = y_tr.iloc[:, j].values\n",
    "        yva = y_va.iloc[:, j].values\n",
    "\n",
    "        if np.unique(ytr).shape[0] < 2 or np.unique(yva).shape[0] < 2:\n",
    "            # degenerate -> keep small iters\n",
    "            best_iters[j] = 200\n",
    "            continue\n",
    "\n",
    "        iters_list = []\n",
    "        pv = np.zeros(x_va.shape[0], dtype=np.float64)\n",
    "\n",
    "        for i, seed in enumerate(seeds, start=1):\n",
    "            print(f\"[OvR-TUNE] {tname} seed={seed} ({i}/{len(seeds)})\")\n",
    "            tr_pool = Pool(x_tr, label=ytr, cat_features=cat_indices)\n",
    "            va_pool = Pool(x_va, label=yva, cat_features=cat_indices)\n",
    "\n",
    "            model = CatBoostClassifier(\n",
    "                loss_function=\"Logloss\",\n",
    "                eval_metric=OVR_EVAL_METRIC,   # Logloss for GPU early stop\n",
    "                iterations=OVR_MAX_ITERS,\n",
    "                learning_rate=0.03,\n",
    "                depth=7,\n",
    "                l2_leaf_reg=8.0,\n",
    "                random_strength=1.0,\n",
    "                bagging_temperature=0.7,\n",
    "                border_count=254,\n",
    "                bootstrap_type=\"Bayesian\",\n",
    "                leaf_estimation_iterations=5,\n",
    "                od_type=\"Iter\",\n",
    "                od_wait=OVR_OD_WAIT,\n",
    "                auto_class_weights=\"Balanced\",\n",
    "                random_seed=seed,\n",
    "                task_type=\"GPU\",\n",
    "                devices=\"0\",\n",
    "                verbose=0,   # too verbose otherwise\n",
    "                allow_writing_files=False,\n",
    "            )\n",
    "            model.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n",
    "\n",
    "            bi = _best_iter_from_model(model, OVR_MAX_ITERS)\n",
    "            iters_list.append(bi)\n",
    "            pv += model.predict(va_pool, prediction_type=\"RawFormulaVal\").reshape(-1) / max(len(seeds), 1)\n",
    "\n",
    "        best_iters[j] = int(np.median(iters_list))\n",
    "        pred_va[:, j] = pv\n",
    "\n",
    "        # optional: quick AUC sanity on holdout for this target\n",
    "        auc_j = safe_auc(yva, sigmoid(pv))\n",
    "        print(f\"[OvR-TUNE] {tname} best_iters={iters_list} median={best_iters[j]} holdout_auc={auc_j:.4f}\")\n",
    "\n",
    "    return best_iters, pred_va\n",
    "\n",
    "\n",
    "def train_ovr_fulltrain(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_test: pd.DataFrame,\n",
    "    cat_indices: List[int],\n",
    "    seeds: List[int],\n",
    "    target_names: List[str],\n",
    "    best_iters: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Train OvR on FULL train per target with fixed iterations (best_iters from tuning).\n",
    "    Returns raw margins on test (shape test x n_targets).\n",
    "    \"\"\"\n",
    "    n_targets = y_train.shape[1]\n",
    "    test_pred = np.zeros((x_test.shape[0], n_targets), dtype=np.float64)\n",
    "    test_pool = Pool(x_test, cat_features=cat_indices)\n",
    "\n",
    "    for j, tname in enumerate(target_names):\n",
    "        iters = int(best_iters[j])\n",
    "        ycol = y_train.iloc[:, j].values\n",
    "        if np.unique(ycol).shape[0] < 2:\n",
    "            # degenerate -> constant\n",
    "            test_pred[:, j] = logit(np.full(x_test.shape[0], ycol.mean(), dtype=np.float64))\n",
    "            continue\n",
    "\n",
    "        pred_test = np.zeros(x_test.shape[0], dtype=np.float64)\n",
    "        train_pool = Pool(x_train, label=ycol, cat_features=cat_indices)\n",
    "\n",
    "        for i, seed in enumerate(seeds, start=1):\n",
    "            print(f\"[OvR-FULL] {tname} seed={seed} ({i}/{len(seeds)}) iters={iters}\")\n",
    "            model = CatBoostClassifier(\n",
    "                loss_function=\"Logloss\",\n",
    "                eval_metric=\"Logloss\",\n",
    "                iterations=iters,\n",
    "                learning_rate=0.03,\n",
    "                depth=7,\n",
    "                l2_leaf_reg=8.0,\n",
    "                random_strength=1.0,\n",
    "                bagging_temperature=0.7,\n",
    "                border_count=254,\n",
    "                bootstrap_type=\"Bayesian\",\n",
    "                leaf_estimation_iterations=5,\n",
    "                auto_class_weights=\"Balanced\",\n",
    "                random_seed=seed,\n",
    "                task_type=\"GPU\",\n",
    "                devices=\"0\",\n",
    "                verbose=0,\n",
    "                allow_writing_files=False,\n",
    "            )\n",
    "            model.fit(train_pool)\n",
    "            pred_test += model.predict(test_pool, prediction_type=\"RawFormulaVal\").reshape(-1) / max(len(seeds), 1)\n",
    "\n",
    "        test_pred[:, j] = pred_test\n",
    "\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Blend tuning (holdout)\n",
    "# =========================\n",
    "def find_best_blend_weight_global(y_true_arr: np.ndarray, p_multi: np.ndarray, p_ovr: np.ndarray) -> Tuple[float, float]:\n",
    "    weights = np.linspace(0.0, 1.0, 21)\n",
    "    best_w, best_auc = 0.5, -1.0\n",
    "    for w in weights:\n",
    "        p_blend = w * p_multi + (1.0 - w) * p_ovr\n",
    "        auc = roc_auc_score(y_true_arr, p_blend, average=\"macro\")\n",
    "        print(f\"Global blend weight={w:.2f} | holdout macro AUC={auc:.6f}\")\n",
    "        if auc > best_auc:\n",
    "            best_auc = float(auc)\n",
    "            best_w = float(w)\n",
    "    return best_w, best_auc\n",
    "\n",
    "\n",
    "def find_best_blend_weight_per_target(\n",
    "    y_true_arr: np.ndarray,\n",
    "    p_multi: np.ndarray,\n",
    "    p_ovr: np.ndarray,\n",
    "    target_names: List[str],\n",
    ") -> Tuple[np.ndarray, float, pd.DataFrame]:\n",
    "    n_targets = y_true_arr.shape[1]\n",
    "\n",
    "    best_weights = np.ones(n_targets, dtype=np.float64)\n",
    "    rows = []\n",
    "\n",
    "    for j in range(n_targets):\n",
    "        yj = y_true_arr[:, j]\n",
    "        auc_multi = safe_auc(yj, p_multi[:, j])\n",
    "        auc_ovr = safe_auc(yj, p_ovr[:, j])\n",
    "\n",
    "        if auc_ovr <= auc_multi + MIN_HOLDOUT_GAIN_FOR_OVR:\n",
    "            best_weights[j] = 1.0\n",
    "            rows.append({\n",
    "                \"target\": target_names[j],\n",
    "                \"best_weight_multi\": 1.0,\n",
    "                \"holdout_auc\": auc_multi,\n",
    "                \"holdout_auc_multi\": auc_multi,\n",
    "                \"holdout_auc_ovr\": auc_ovr,\n",
    "                \"ovr_used\": 0,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        best_w_j = 1.0\n",
    "        best_auc_j = auc_multi\n",
    "        for w in BLEND_GRID:\n",
    "            pj = w * p_multi[:, j] + (1.0 - w) * p_ovr[:, j]\n",
    "            auc_j = safe_auc(yj, pj)\n",
    "            if auc_j > best_auc_j:\n",
    "                best_auc_j = auc_j\n",
    "                best_w_j = float(w)\n",
    "\n",
    "        best_w_j = max(best_w_j, MIN_MULTI_WEIGHT)\n",
    "        best_weights[j] = best_w_j\n",
    "        rows.append({\n",
    "            \"target\": target_names[j],\n",
    "            \"best_weight_multi\": best_w_j,\n",
    "            \"holdout_auc\": best_auc_j,\n",
    "            \"holdout_auc_multi\": auc_multi,\n",
    "            \"holdout_auc_ovr\": auc_ovr,\n",
    "            \"ovr_used\": int(best_w_j < 1.0),\n",
    "        })\n",
    "\n",
    "    p_blend = p_multi * best_weights.reshape(1, -1) + p_ovr * (1.0 - best_weights.reshape(1, -1))\n",
    "    macro_auc = roc_auc_score(y_true_arr, p_blend, average=\"macro\")\n",
    "\n",
    "    report_df = pd.DataFrame(rows)\n",
    "    return best_weights, float(macro_auc), report_df\n",
    "\n",
    "\n",
    "def per_target_auc_frame(y_true: np.ndarray, y_pred: np.ndarray, target_names: List[str], score_col: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for j, t in enumerate(target_names):\n",
    "        rows.append({\"target\": t, score_col: safe_auc(y_true[:, j], y_pred[:, j])})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def patch_params_for_target(pos_rate: float) -> Dict[str, float]:\n",
    "    if pos_rate < 0.005:\n",
    "        return {\"iterations\": min(PATCH_MAX_ITERS, 1600), \"depth\": 7, \"learning_rate\": 0.07, \"l2_leaf_reg\": 28.0, \"od_wait\": 120}\n",
    "    if pos_rate < 0.05:\n",
    "        return {\"iterations\": min(PATCH_MAX_ITERS, 1900), \"depth\": 7, \"learning_rate\": 0.06, \"l2_leaf_reg\": 24.0, \"od_wait\": 140}\n",
    "    return {\"iterations\": PATCH_MAX_ITERS, \"depth\": 8, \"learning_rate\": 0.05, \"l2_leaf_reg\": 20.0, \"od_wait\": PATCH_OD_WAIT}\n",
    "\n",
    "\n",
    "def rank_blend_1d(base_scores: np.ndarray, patch_scores: np.ndarray, patch_weight: float) -> np.ndarray:\n",
    "    base_r = rank_normalize_2d(base_scores.reshape(-1, 1)).reshape(-1)\n",
    "    patch_r = rank_normalize_2d(patch_scores.reshape(-1, 1)).reshape(-1)\n",
    "    blend_r = (1.0 - patch_weight) * base_r + patch_weight * patch_r\n",
    "    return logit(blend_r)\n",
    "\n",
    "\n",
    "def apply_targeted_patch_stage(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_test: pd.DataFrame,\n",
    "    cat_indices: List[int],\n",
    "    target_names: List[str],\n",
    "    base_va_logits: np.ndarray,\n",
    "    base_test_logits: np.ndarray,\n",
    "    tune_seed: int,\n",
    ") -> Tuple[np.ndarray, pd.DataFrame]:\n",
    "    y_sum = y_train.sum(axis=1).values\n",
    "    bins = pd.cut(y_sum, bins=[-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 100], labels=False).astype(int)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=PATCH_VAL_SHARE, random_state=tune_seed)\n",
    "    tr_idx, va_idx = next(sss.split(np.zeros((len(y_train), 1)), bins))\n",
    "\n",
    "    x_tr, x_va = x_train.iloc[tr_idx], x_train.iloc[va_idx]\n",
    "    y_tr, y_va = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "\n",
    "    base_va_logits = np.asarray(base_va_logits, dtype=np.float64)\n",
    "    base_va_prob = sigmoid(base_va_logits)\n",
    "    y_va_arr = y_va.values\n",
    "\n",
    "    auc_df = per_target_auc_frame(y_va_arr, base_va_prob, target_names, \"base_holdout_auc\")\n",
    "    worst_targets = auc_df.sort_values(\"base_holdout_auc\").head(PATCH_TOP_K)[\"target\"].tolist()\n",
    "    print(f\"[PATCH] selected worst targets: {len(worst_targets)}\")\n",
    "\n",
    "    patched_logits = np.asarray(base_test_logits, dtype=np.float64).copy()\n",
    "    reports = []\n",
    "\n",
    "    for tname in worst_targets:\n",
    "        j = target_names.index(tname)\n",
    "        ytr_col = y_tr.iloc[:, j].values\n",
    "        yva_col = y_va.iloc[:, j].values\n",
    "        if np.unique(ytr_col).shape[0] < 2 or np.unique(yva_col).shape[0] < 2:\n",
    "            reports.append({\"target\": tname, \"patched\": 0, \"reason\": \"degenerate\"})\n",
    "            continue\n",
    "\n",
    "        pos_rate = float(y_train.iloc[:, j].mean())\n",
    "        pp = patch_params_for_target(pos_rate)\n",
    "        va_patch_logits = np.zeros(len(x_va), dtype=np.float64)\n",
    "        test_patch_logits = np.zeros(len(x_test), dtype=np.float64)\n",
    "\n",
    "        for seed in PATCH_SEEDS:\n",
    "            model = CatBoostClassifier(\n",
    "                loss_function=\"Logloss\",\n",
    "                eval_metric=\"Logloss\",\n",
    "                iterations=int(pp[\"iterations\"]),\n",
    "                learning_rate=float(pp[\"learning_rate\"]),\n",
    "                depth=int(pp[\"depth\"]),\n",
    "                l2_leaf_reg=float(pp[\"l2_leaf_reg\"]),\n",
    "                random_strength=1.0,\n",
    "                bootstrap_type=\"Bernoulli\",\n",
    "                subsample=0.88,\n",
    "                od_type=\"Iter\",\n",
    "                od_wait=int(pp[\"od_wait\"]),\n",
    "                auto_class_weights=\"Balanced\",\n",
    "                random_seed=int(seed),\n",
    "                task_type=\"GPU\",\n",
    "                devices=\"0\",\n",
    "                verbose=0,\n",
    "                allow_writing_files=False,\n",
    "            )\n",
    "            tr_pool = Pool(x_tr, label=ytr_col, cat_features=cat_indices)\n",
    "            va_pool = Pool(x_va, label=yva_col, cat_features=cat_indices)\n",
    "            te_pool = Pool(x_test, cat_features=cat_indices)\n",
    "            model.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n",
    "            va_patch_logits += model.predict(va_pool, prediction_type=\"RawFormulaVal\").reshape(-1) / max(len(PATCH_SEEDS), 1)\n",
    "            test_patch_logits += model.predict(te_pool, prediction_type=\"RawFormulaVal\").reshape(-1) / max(len(PATCH_SEEDS), 1)\n",
    "\n",
    "        base_va_target_logits = base_va_logits[:, j]\n",
    "        best_w = 0.0\n",
    "        best_auc = safe_auc(yva_col, sigmoid(base_va_target_logits))\n",
    "\n",
    "        for w in PATCH_BLEND_GRID:\n",
    "            trial_logits = rank_blend_1d(base_va_target_logits, va_patch_logits, patch_weight=float(w))\n",
    "            trial_auc = safe_auc(yva_col, sigmoid(trial_logits))\n",
    "            if trial_auc > best_auc:\n",
    "                best_auc = trial_auc\n",
    "                best_w = float(w)\n",
    "\n",
    "        base_auc = safe_auc(yva_col, sigmoid(base_va_target_logits))\n",
    "        gain = best_auc - base_auc\n",
    "        if gain >= PATCH_MIN_GAIN and best_w > 0:\n",
    "            patched_logits[:, j] = rank_blend_1d(patched_logits[:, j], test_patch_logits, patch_weight=best_w)\n",
    "            reports.append({\n",
    "                \"target\": tname,\n",
    "                \"patched\": 1,\n",
    "                \"patch_weight\": best_w,\n",
    "                \"base_holdout_auc\": base_auc,\n",
    "                \"patched_holdout_auc\": best_auc,\n",
    "                \"gain\": gain,\n",
    "                \"pos_rate\": pos_rate,\n",
    "            })\n",
    "            print(f\"[PATCH] {tname}: gain={gain:.6f}, w={best_w:.2f}\")\n",
    "        else:\n",
    "            reports.append({\n",
    "                \"target\": tname,\n",
    "                \"patched\": 0,\n",
    "                \"patch_weight\": 0.0,\n",
    "                \"base_holdout_auc\": base_auc,\n",
    "                \"patched_holdout_auc\": best_auc,\n",
    "                \"gain\": gain,\n",
    "                \"pos_rate\": pos_rate,\n",
    "            })\n",
    "\n",
    "    report_df = pd.DataFrame(reports)\n",
    "    return patched_logits, report_df\n",
    "\n",
    "\n",
    "def build_submission(sample_submit: pd.DataFrame, preds: np.ndarray, out_path: Path) -> None:\n",
    "    # ensure schema (order) is exactly sample\n",
    "    sub = sample_submit.copy()\n",
    "    sub.iloc[:, 1:] = preds.astype(np.float64)\n",
    "    # keep exact dtype for customer_id as sample\n",
    "    if sub[\"customer_id\"].dtype != sample_submit[\"customer_id\"].dtype:\n",
    "        sub[\"customer_id\"] = sub[\"customer_id\"].astype(sample_submit[\"customer_id\"].dtype)\n",
    "    sub.to_parquet(out_path, index=False)\n",
    "    print(f\"Saved submission: {out_path} | shape={sub.shape}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main() -> None:\n",
    "    print(\"CONFIG:\")\n",
    "    print(f\"  DATA_DIR={DATA_DIR}\")\n",
    "    print(f\"  OUTPUT_PATH={OUTPUT_PATH}\")\n",
    "    print(f\"  MULTI_SEEDS={MULTI_SEEDS}, OVR_SEEDS={OVR_SEEDS}\")\n",
    "    print(f\"  HOLDOUT size={TUNE_HOLDOUT_SIZE} seed={TUNE_SEED}\")\n",
    "    print(f\"  AUTO_TUNE_BLEND_WEIGHT={AUTO_TUNE_BLEND_WEIGHT}\")\n",
    "    print(f\"  USE_PER_TARGET_BLEND={USE_PER_TARGET_BLEND}\")\n",
    "    print(f\"  APPLY_RANK_BLEND={APPLY_RANK_BLEND}\")\n",
    "    print(f\"  MIN_HOLDOUT_GAIN_FOR_OVR={MIN_HOLDOUT_GAIN_FOR_OVR}\")\n",
    "    print(f\"  ENABLE_PATCH_STAGE={ENABLE_PATCH_STAGE}, PATCH_TOP_K={PATCH_TOP_K}\")\n",
    "\n",
    "    data_dir = resolve_data_dir()\n",
    "    print(f\"Using data dir: {data_dir}\")\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    train_main, train_extra, test_main, test_extra, target, sample_submit = load_data(data_dir)\n",
    "\n",
    "    print(\"Merging features...\")\n",
    "    train_full = merge_features(train_main, train_extra)\n",
    "    test_full = merge_features(test_main, test_extra)\n",
    "\n",
    "    print(\"Running EDA...\")\n",
    "    run_eda(train_full, test_full, target, EDA_REPORT_PATH)\n",
    "\n",
    "    print(\"Applying feature hygiene...\")\n",
    "    train_full, test_full, _ = apply_feature_hygiene(train_full, test_full)\n",
    "\n",
    "    print(\"Preprocessing categorical features...\")\n",
    "    train_full, test_full, cat_indices, feature_cols = preprocess_cats(train_full, test_full)\n",
    "\n",
    "    # align target to train_full by customer_id\n",
    "    target_cols = [c for c in target.columns if c != \"customer_id\"]\n",
    "    if \"customer_id\" in train_full.columns and \"customer_id\" in target.columns:\n",
    "        target = target.sort_values(\"customer_id\").reset_index(drop=True)\n",
    "        train_full = train_full.sort_values(\"customer_id\").reset_index(drop=True)\n",
    "        assert np.all(train_full[\"customer_id\"].values == target[\"customer_id\"].values), \"customer_id mismatch after sort\"\n",
    "    y_train = target[target_cols]\n",
    "\n",
    "    x_train = train_full[feature_cols]\n",
    "    x_test = test_full[feature_cols]\n",
    "\n",
    "    # ---------- Holdout split for tuning ----------\n",
    "    y_sum = y_train.sum(axis=1).values\n",
    "    bins = pd.cut(y_sum, bins=[-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 100], labels=False).astype(int)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=TUNE_HOLDOUT_SIZE, random_state=TUNE_SEED)\n",
    "    tr_idx, va_idx = next(sss.split(np.zeros((len(y_train), 1)), bins))\n",
    "\n",
    "    x_tr, x_va = x_train.iloc[tr_idx], x_train.iloc[va_idx]\n",
    "    y_tr, y_va = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "    y_va_arr = y_va.values\n",
    "\n",
    "    print(\"\\n[TUNE] Finding best iterations with early stopping on holdout...\")\n",
    "\n",
    "    best_iter_multi, pred_multi_va_raw = train_multilabel_tune_best_iter(\n",
    "        x_tr=x_tr, y_tr=y_tr, x_va=x_va, y_va=y_va,\n",
    "        cat_indices=cat_indices, seeds=MULTI_SEEDS\n",
    "    )\n",
    "\n",
    "    best_iters_ovr, pred_ovr_va_raw = train_ovr_tune_best_iters(\n",
    "        x_tr=x_tr, y_tr=y_tr, x_va=x_va, y_va=y_va,\n",
    "        cat_indices=cat_indices, seeds=OVR_SEEDS, target_names=target_cols\n",
    "    )\n",
    "\n",
    "    # Save best iters report\n",
    "    iters_df = pd.DataFrame({\n",
    "        \"target\": [\"__MULTI__\"] + target_cols,\n",
    "        \"best_iter\": [best_iter_multi] + best_iters_ovr.tolist()\n",
    "    })\n",
    "    iters_df.to_csv(BEST_ITERS_REPORT_PATH, index=False)\n",
    "    print(f\"Saved best iters: {BEST_ITERS_REPORT_PATH}\")\n",
    "\n",
    "    # ---------- Tune blend weights on holdout ----------\n",
    "    p_multi_va = sigmoid(pred_multi_va_raw)\n",
    "    p_ovr_va = sigmoid(pred_ovr_va_raw)\n",
    "\n",
    "    if APPLY_RANK_BLEND:\n",
    "        p_multi_va_for_blend = rank_normalize_2d(p_multi_va)\n",
    "        p_ovr_va_for_blend = rank_normalize_2d(p_ovr_va)\n",
    "    else:\n",
    "        p_multi_va_for_blend = p_multi_va\n",
    "        p_ovr_va_for_blend = p_ovr_va\n",
    "\n",
    "    if AUTO_TUNE_BLEND_WEIGHT:\n",
    "        if USE_PER_TARGET_BLEND:\n",
    "            best_w_vec, macro_auc, report_df = find_best_blend_weight_per_target(\n",
    "                y_true_arr=y_va_arr,\n",
    "                p_multi=p_multi_va_for_blend,\n",
    "                p_ovr=p_ovr_va_for_blend,\n",
    "                target_names=target_cols,\n",
    "            )\n",
    "            report_df.to_csv(BLEND_WEIGHTS_REPORT_PATH, index=False)\n",
    "            print(f\"[BLEND] Per-target tuned on holdout. macro AUC={macro_auc:.6f}\")\n",
    "            print(f\"Saved blend weights report: {BLEND_WEIGHTS_REPORT_PATH}\")\n",
    "        else:\n",
    "            best_w, best_auc = find_best_blend_weight_global(y_va_arr, p_multi_va_for_blend, p_ovr_va_for_blend)\n",
    "            best_w_vec = None\n",
    "            print(f\"[BLEND] Best global w={best_w:.3f} macro AUC={best_auc:.6f}\")\n",
    "    else:\n",
    "        best_w_vec = None\n",
    "        best_w = DEFAULT_BLEND_WEIGHT_MULTI\n",
    "        print(f\"[BLEND] Using default w={best_w:.3f}\")\n",
    "\n",
    "    if AUTO_TUNE_BLEND_WEIGHT:\n",
    "        if USE_PER_TARGET_BLEND and best_w_vec is not None:\n",
    "            p_blend_va = p_multi_va_for_blend * best_w_vec.reshape(1, -1) + p_ovr_va_for_blend * (1.0 - best_w_vec.reshape(1, -1))\n",
    "        else:\n",
    "            p_blend_va = best_w * p_multi_va_for_blend + (1.0 - best_w) * p_ovr_va_for_blend\n",
    "    else:\n",
    "        p_blend_va = DEFAULT_BLEND_WEIGHT_MULTI * p_multi_va_for_blend + (1.0 - DEFAULT_BLEND_WEIGHT_MULTI) * p_ovr_va_for_blend\n",
    "    base_va_logits_for_patch = logit(p_blend_va)\n",
    "\n",
    "    # ---------- FINAL full-train models with tuned iterations ----------\n",
    "    print(\"\\n[FINAL] Training MultiLogloss on FULL train with best_iter...\")\n",
    "    test_multi_raw = train_multilabel_fulltrain(\n",
    "        x_train=x_train, y_train=y_train, x_test=x_test,\n",
    "        cat_indices=cat_indices, seeds=MULTI_SEEDS, iterations=best_iter_multi\n",
    "    )\n",
    "\n",
    "    print(\"\\n[FINAL] Training OvR on FULL train with per-target best_iters...\")\n",
    "    test_ovr_raw = train_ovr_fulltrain(\n",
    "        x_train=x_train, y_train=y_train, x_test=x_test,\n",
    "        cat_indices=cat_indices, seeds=OVR_SEEDS, target_names=target_cols, best_iters=best_iters_ovr\n",
    "    )\n",
    "\n",
    "    p_multi_test = sigmoid(test_multi_raw)\n",
    "    p_ovr_test = sigmoid(test_ovr_raw)\n",
    "\n",
    "    if APPLY_RANK_BLEND:\n",
    "        p_multi_test_for_blend = rank_normalize_2d(p_multi_test)\n",
    "        p_ovr_test_for_blend = rank_normalize_2d(p_ovr_test)\n",
    "    else:\n",
    "        p_multi_test_for_blend = p_multi_test\n",
    "        p_ovr_test_for_blend = p_ovr_test\n",
    "\n",
    "    if AUTO_TUNE_BLEND_WEIGHT:\n",
    "        if USE_PER_TARGET_BLEND and best_w_vec is not None:\n",
    "            p_blend_test = p_multi_test_for_blend * best_w_vec.reshape(1, -1) + p_ovr_test_for_blend * (1.0 - best_w_vec.reshape(1, -1))\n",
    "        else:\n",
    "            p_blend_test = best_w * p_multi_test_for_blend + (1.0 - best_w) * p_ovr_test_for_blend\n",
    "    else:\n",
    "        p_blend_test = DEFAULT_BLEND_WEIGHT_MULTI * p_multi_test_for_blend + (1.0 - DEFAULT_BLEND_WEIGHT_MULTI) * p_ovr_test_for_blend\n",
    "\n",
    "    pred_final = logit(p_blend_test)\n",
    "\n",
    "    if ENABLE_PATCH_STAGE:\n",
    "        print(\"[PATCH] Running targeted patch stage...\")\n",
    "        patched_logits, patch_report = apply_targeted_patch_stage(\n",
    "            x_train=x_train,\n",
    "            y_train=y_train,\n",
    "            x_test=x_test,\n",
    "            cat_indices=cat_indices,\n",
    "            target_names=target_cols,\n",
    "            base_va_logits=base_va_logits_for_patch,\n",
    "            base_test_logits=pred_final,\n",
    "            tune_seed=TUNE_SEED + 17,\n",
    "        )\n",
    "        patch_report.to_csv(\"patch_stage_report.csv\", index=False)\n",
    "        print(\"[PATCH] Saved patch report: patch_stage_report.csv\")\n",
    "        pred_final = patched_logits\n",
    "\n",
    "    build_submission(sample_submit, pred_final, OUTPUT_PATH)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-24T07:35:55.491152Z",
     "iopub.execute_input": "2026-02-24T07:35:55.491604Z",
     "iopub.status.idle": "2026-02-24T14:11:46.691164Z",
     "shell.execute_reply.started": "2026-02-24T07:35:55.491587Z",
     "shell.execute_reply": "2026-02-24T14:11:46.690702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "CONFIG:\n  DATA_DIR=/kaggle/input/data-fusion-contest-2026\n  OUTPUT_PATH=submission.parquet\n  MULTI_SEEDS=[42], OVR_SEEDS=[2026]\n  HOLDOUT size=0.05 seed=42\n  AUTO_TUNE_BLEND_WEIGHT=True\n  USE_PER_TARGET_BLEND=True\nUsing data dir: /kaggle/input/data-fusion-contest-2026\nLoading data...\nMerging features...\nRunning EDA...\nEDA report saved to: eda_report.md\nApplying feature hygiene...\nFeature hygiene stats: {'dropped_total_unique': 177, 'dropped_const': 0, 'dropped_near_const': 65, 'dropped_ultra_missing': 177, 'overlap_nearconst_ultramissing': 65}\nPreprocessing categorical features...\n\n[TUNE] Finding best iterations with early stopping on holdout...\n[Multi-TUNE] seed=42 (1/1)\n0:\tlearn: 0.6336614\ttest: 0.6336422\tbest: 0.6336422 (0)\ttotal: 859ms\tremaining: 2h 23m 9s\n300:\tlearn: 0.0846191\ttest: 0.0852740\tbest: 0.0852740 (300)\ttotal: 4m 11s\tremaining: 2h 15m 7s\n600:\tlearn: 0.0817943\ttest: 0.0835613\tbest: 0.0835613 (600)\ttotal: 8m 20s\tremaining: 2h 10m 33s\n900:\tlearn: 0.0799346\ttest: 0.0827614\tbest: 0.0827614 (900)\ttotal: 12m 29s\tremaining: 2h 6m 5s\n1200:\tlearn: 0.0785317\ttest: 0.0822892\tbest: 0.0822892 (1200)\ttotal: 16m 31s\tremaining: 2h 1m 1s\n1500:\tlearn: 0.0775153\ttest: 0.0820250\tbest: 0.0820250 (1500)\ttotal: 20m 23s\tremaining: 1h 55m 29s\n1800:\tlearn: 0.0767997\ttest: 0.0818592\tbest: 0.0818592 (1800)\ttotal: 24m 6s\tremaining: 1h 49m 42s\n2100:\tlearn: 0.0761221\ttest: 0.0817239\tbest: 0.0817239 (2100)\ttotal: 27m 47s\tremaining: 1h 44m 28s\n2400:\tlearn: 0.0755571\ttest: 0.0816195\tbest: 0.0816195 (2400)\ttotal: 31m 24s\tremaining: 1h 39m 24s\n2700:\tlearn: 0.0750830\ttest: 0.0815476\tbest: 0.0815476 (2699)\ttotal: 34m 57s\tremaining: 1h 34m 29s\n3000:\tlearn: 0.0746270\ttest: 0.0814837\tbest: 0.0814837 (3000)\ttotal: 38m 31s\tremaining: 1h 29m 50s\n3300:\tlearn: 0.0741609\ttest: 0.0814232\tbest: 0.0814232 (3299)\ttotal: 42m 5s\tremaining: 1h 25m 26s\n3600:\tlearn: 0.0736969\ttest: 0.0813678\tbest: 0.0813678 (3600)\ttotal: 45m 41s\tremaining: 1h 21m 11s\n3900:\tlearn: 0.0732715\ttest: 0.0813190\tbest: 0.0813190 (3900)\ttotal: 49m 14s\tremaining: 1h 16m 59s\n4200:\tlearn: 0.0728735\ttest: 0.0812781\tbest: 0.0812781 (4200)\ttotal: 52m 48s\tremaining: 1h 12m 53s\n4500:\tlearn: 0.0724460\ttest: 0.0812390\tbest: 0.0812389 (4495)\ttotal: 56m 23s\tremaining: 1h 8m 53s\n4800:\tlearn: 0.0720463\ttest: 0.0812043\tbest: 0.0812043 (4800)\ttotal: 59m 57s\tremaining: 1h 4m 55s\n5100:\tlearn: 0.0716869\ttest: 0.0811702\tbest: 0.0811701 (5099)\ttotal: 1h 3m 30s\tremaining: 1h 59s\n5400:\tlearn: 0.0713100\ttest: 0.0811448\tbest: 0.0811448 (5400)\ttotal: 1h 7m 4s\tremaining: 57m 7s\n5700:\tlearn: 0.0709167\ttest: 0.0811231\tbest: 0.0811229 (5699)\ttotal: 1h 10m 40s\tremaining: 53m 17s\n6000:\tlearn: 0.0705565\ttest: 0.0811064\tbest: 0.0811064 (6000)\ttotal: 1h 14m 15s\tremaining: 49m 28s\n6300:\tlearn: 0.0701811\ttest: 0.0810892\tbest: 0.0810892 (6299)\ttotal: 1h 17m 50s\tremaining: 45m 42s\n6600:\tlearn: 0.0698281\ttest: 0.0810768\tbest: 0.0810765 (6591)\ttotal: 1h 21m 25s\tremaining: 41m 55s\n6900:\tlearn: 0.0694544\ttest: 0.0810655\tbest: 0.0810655 (6900)\ttotal: 1h 25m 3s\tremaining: 38m 11s\n7200:\tlearn: 0.0690985\ttest: 0.0810476\tbest: 0.0810475 (7199)\ttotal: 1h 28m 39s\tremaining: 34m 27s\n7500:\tlearn: 0.0687226\ttest: 0.0810323\tbest: 0.0810322 (7498)\ttotal: 1h 32m 18s\tremaining: 30m 45s\n7800:\tlearn: 0.0683536\ttest: 0.0810197\tbest: 0.0810197 (7800)\ttotal: 1h 35m 55s\tremaining: 27m 2s\n8100:\tlearn: 0.0679960\ttest: 0.0810127\tbest: 0.0810113 (8081)\ttotal: 1h 39m 33s\tremaining: 23m 20s\n8400:\tlearn: 0.0676151\ttest: 0.0810106\tbest: 0.0810106 (8400)\ttotal: 1h 43m 14s\tremaining: 19m 38s\n8700:\tlearn: 0.0672625\ttest: 0.0810070\tbest: 0.0810064 (8632)\ttotal: 1h 46m 52s\tremaining: 15m 57s\n9000:\tlearn: 0.0669190\ttest: 0.0810060\tbest: 0.0810043 (8903)\ttotal: 1h 50m 29s\tremaining: 12m 15s\nbestTest = 0.08100427734\nbestIteration = 8903\nShrink model to first 8904 iterations.\n[Multi-TUNE] best_iter candidates=[8904] -> median=8904\n[OvR-TUNE] target_1_1 seed=2026 (1/1)\n[OvR-TUNE] target_1_1 best_iters=[910] median=910 holdout_auc=0.9133\n[OvR-TUNE] target_1_2 seed=2026 (1/1)\n[OvR-TUNE] target_1_2 best_iters=[139] median=139 holdout_auc=0.8125\n[OvR-TUNE] target_1_3 seed=2026 (1/1)\n[OvR-TUNE] target_1_3 best_iters=[1088] median=1088 holdout_auc=0.8744\n[OvR-TUNE] target_1_4 seed=2026 (1/1)\n[OvR-TUNE] target_1_4 best_iters=[1327] median=1327 holdout_auc=0.8595\n[OvR-TUNE] target_1_5 seed=2026 (1/1)\n[OvR-TUNE] target_1_5 best_iters=[127] median=127 holdout_auc=0.8985\n[OvR-TUNE] target_2_1 seed=2026 (1/1)\n[OvR-TUNE] target_2_1 best_iters=[199] median=199 holdout_auc=0.8288\n[OvR-TUNE] target_2_2 seed=2026 (1/1)\n[OvR-TUNE] target_2_2 best_iters=[1317] median=1317 holdout_auc=0.9386\n[OvR-TUNE] target_2_3 seed=2026 (1/1)\n[OvR-TUNE] target_2_3 best_iters=[96] median=96 holdout_auc=0.8352\n[OvR-TUNE] target_2_4 seed=2026 (1/1)\n[OvR-TUNE] target_2_4 best_iters=[294] median=294 holdout_auc=0.7510\n[OvR-TUNE] target_2_5 seed=2026 (1/1)\n[OvR-TUNE] target_2_5 best_iters=[82] median=82 holdout_auc=0.7535\n[OvR-TUNE] target_2_6 seed=2026 (1/1)\n[OvR-TUNE] target_2_6 best_iters=[325] median=325 holdout_auc=0.7554\n[OvR-TUNE] target_2_7 seed=2026 (1/1)\n[OvR-TUNE] target_2_7 best_iters=[8] median=8 holdout_auc=0.7665\n[OvR-TUNE] target_2_8 seed=2026 (1/1)\n[OvR-TUNE] target_2_8 best_iters=[97] median=97 holdout_auc=0.9993\n[OvR-TUNE] target_3_1 seed=2026 (1/1)\n[OvR-TUNE] target_3_1 best_iters=[3225] median=3225 holdout_auc=0.7039\n[OvR-TUNE] target_3_2 seed=2026 (1/1)\n[OvR-TUNE] target_3_2 best_iters=[3719] median=3719 holdout_auc=0.9140\n[OvR-TUNE] target_3_3 seed=2026 (1/1)\n[OvR-TUNE] target_3_3 best_iters=[54] median=54 holdout_auc=0.7439\n[OvR-TUNE] target_3_4 seed=2026 (1/1)\n[OvR-TUNE] target_3_4 best_iters=[127] median=127 holdout_auc=0.9447\n[OvR-TUNE] target_3_5 seed=2026 (1/1)\n[OvR-TUNE] target_3_5 best_iters=[113] median=113 holdout_auc=0.9653\n[OvR-TUNE] target_4_1 seed=2026 (1/1)\n[OvR-TUNE] target_4_1 best_iters=[263] median=263 holdout_auc=0.8599\n[OvR-TUNE] target_5_1 seed=2026 (1/1)\n[OvR-TUNE] target_5_1 best_iters=[248] median=248 holdout_auc=0.7542\n[OvR-TUNE] target_5_2 seed=2026 (1/1)\n[OvR-TUNE] target_5_2 best_iters=[109] median=109 holdout_auc=0.7182\n[OvR-TUNE] target_6_1 seed=2026 (1/1)\n[OvR-TUNE] target_6_1 best_iters=[310] median=310 holdout_auc=0.7347\n[OvR-TUNE] target_6_2 seed=2026 (1/1)\n[OvR-TUNE] target_6_2 best_iters=[321] median=321 holdout_auc=0.7233\n[OvR-TUNE] target_6_3 seed=2026 (1/1)\n[OvR-TUNE] target_6_3 best_iters=[243] median=243 holdout_auc=0.7658\n[OvR-TUNE] target_6_4 seed=2026 (1/1)\n[OvR-TUNE] target_6_4 best_iters=[565] median=565 holdout_auc=0.8817\n[OvR-TUNE] target_6_5 seed=2026 (1/1)\n[OvR-TUNE] target_6_5 best_iters=[85] median=85 holdout_auc=0.9625\n[OvR-TUNE] target_7_1 seed=2026 (1/1)\n[OvR-TUNE] target_7_1 best_iters=[2196] median=2196 holdout_auc=0.8174\n[OvR-TUNE] target_7_2 seed=2026 (1/1)\n[OvR-TUNE] target_7_2 best_iters=[1795] median=1795 holdout_auc=0.8687\n[OvR-TUNE] target_7_3 seed=2026 (1/1)\n[OvR-TUNE] target_7_3 best_iters=[149] median=149 holdout_auc=0.8065\n[OvR-TUNE] target_8_1 seed=2026 (1/1)\n[OvR-TUNE] target_8_1 best_iters=[5993] median=5993 holdout_auc=0.9839\n[OvR-TUNE] target_8_2 seed=2026 (1/1)\n[OvR-TUNE] target_8_2 best_iters=[2505] median=2505 holdout_auc=0.8760\n[OvR-TUNE] target_8_3 seed=2026 (1/1)\n[OvR-TUNE] target_8_3 best_iters=[1057] median=1057 holdout_auc=0.8915\n[OvR-TUNE] target_9_1 seed=2026 (1/1)\n[OvR-TUNE] target_9_1 best_iters=[167] median=167 holdout_auc=0.7654\n[OvR-TUNE] target_9_2 seed=2026 (1/1)\n[OvR-TUNE] target_9_2 best_iters=[1259] median=1259 holdout_auc=0.8438\n[OvR-TUNE] target_9_3 seed=2026 (1/1)\n[OvR-TUNE] target_9_3 best_iters=[324] median=324 holdout_auc=0.6799\n[OvR-TUNE] target_9_4 seed=2026 (1/1)\n[OvR-TUNE] target_9_4 best_iters=[174] median=174 holdout_auc=0.9239\n[OvR-TUNE] target_9_5 seed=2026 (1/1)\n[OvR-TUNE] target_9_5 best_iters=[259] median=259 holdout_auc=0.8680\n[OvR-TUNE] target_9_6 seed=2026 (1/1)\n[OvR-TUNE] target_9_6 best_iters=[4889] median=4889 holdout_auc=0.6982\n[OvR-TUNE] target_9_7 seed=2026 (1/1)\n[OvR-TUNE] target_9_7 best_iters=[2676] median=2676 holdout_auc=0.7772\n[OvR-TUNE] target_9_8 seed=2026 (1/1)\n[OvR-TUNE] target_9_8 best_iters=[938] median=938 holdout_auc=0.9420\n[OvR-TUNE] target_10_1 seed=2026 (1/1)\n[OvR-TUNE] target_10_1 best_iters=[5880] median=5880 holdout_auc=0.7632\nSaved best iters: best_iters.csv\n[BLEND] Per-target tuned on holdout. macro AUC=0.841882\nSaved blend weights report: blend_weights.csv\n\n[FINAL] Training MultiLogloss on FULL train with best_iter...\n[Multi-FULL] seed=42 (1/1) iters=8904\n0:\tlearn: 0.6336272\ttotal: 828ms\tremaining: 2h 2m 51s\n300:\tlearn: 0.0846320\ttotal: 4m 14s\tremaining: 2h 1m 25s\n600:\tlearn: 0.0818341\ttotal: 8m 28s\tremaining: 1h 57m 8s\n900:\tlearn: 0.0799959\ttotal: 12m 40s\tremaining: 1h 52m 38s\n1200:\tlearn: 0.0786394\ttotal: 16m 46s\tremaining: 1h 47m 37s\n1500:\tlearn: 0.0776864\ttotal: 20m 42s\tremaining: 1h 42m 5s\n1800:\tlearn: 0.0769751\ttotal: 24m 26s\tremaining: 1h 36m 21s\n2100:\tlearn: 0.0763633\ttotal: 28m 8s\tremaining: 1h 31m 7s\n2400:\tlearn: 0.0758177\ttotal: 31m 47s\tremaining: 1h 26m 7s\n2700:\tlearn: 0.0753407\ttotal: 35m 24s\tremaining: 1h 21m 19s\n3000:\tlearn: 0.0748912\ttotal: 39m 1s\tremaining: 1h 16m 44s\n3300:\tlearn: 0.0744611\ttotal: 42m 37s\tremaining: 1h 12m 21s\n3600:\tlearn: 0.0740401\ttotal: 46m 13s\tremaining: 1h 8m 4s\n3900:\tlearn: 0.0736631\ttotal: 49m 47s\tremaining: 1h 3m 51s\n4200:\tlearn: 0.0732899\ttotal: 53m 22s\tremaining: 59m 44s\n4500:\tlearn: 0.0728962\ttotal: 56m 58s\tremaining: 55m 44s\n4800:\tlearn: 0.0725019\ttotal: 1h 36s\tremaining: 51m 47s\n5100:\tlearn: 0.0721197\ttotal: 1h 4m 13s\tremaining: 47m 53s\n5400:\tlearn: 0.0717654\ttotal: 1h 7m 49s\tremaining: 43m 59s\n5700:\tlearn: 0.0713885\ttotal: 1h 11m 27s\tremaining: 40m 8s\n6000:\tlearn: 0.0709979\ttotal: 1h 15m 7s\tremaining: 36m 20s\n6300:\tlearn: 0.0706612\ttotal: 1h 18m 43s\tremaining: 32m 31s\n6600:\tlearn: 0.0703056\ttotal: 1h 22m 22s\tremaining: 28m 44s\n6900:\tlearn: 0.0699481\ttotal: 1h 26m 2s\tremaining: 24m 58s\n7200:\tlearn: 0.0695960\ttotal: 1h 29m 42s\tremaining: 21m 12s\n7500:\tlearn: 0.0692423\ttotal: 1h 33m 23s\tremaining: 17m 28s\n7800:\tlearn: 0.0688838\ttotal: 1h 37m 3s\tremaining: 13m 43s\n8100:\tlearn: 0.0684999\ttotal: 1h 40m 48s\tremaining: 9m 59s\n8400:\tlearn: 0.0681593\ttotal: 1h 44m 27s\tremaining: 6m 15s\n8700:\tlearn: 0.0678122\ttotal: 1h 48m 9s\tremaining: 2m 31s\n8903:\tlearn: 0.0675687\ttotal: 1h 50m 39s\tremaining: 0us\n\n[FINAL] Training OvR on FULL train with per-target best_iters...\n[OvR-FULL] target_1_1 seed=2026 (1/1) iters=910\n[OvR-FULL] target_1_2 seed=2026 (1/1) iters=139\n[OvR-FULL] target_1_3 seed=2026 (1/1) iters=1088\n[OvR-FULL] target_1_4 seed=2026 (1/1) iters=1327\n[OvR-FULL] target_1_5 seed=2026 (1/1) iters=127\n[OvR-FULL] target_2_1 seed=2026 (1/1) iters=199\n[OvR-FULL] target_2_2 seed=2026 (1/1) iters=1317\n[OvR-FULL] target_2_3 seed=2026 (1/1) iters=96\n[OvR-FULL] target_2_4 seed=2026 (1/1) iters=294\n[OvR-FULL] target_2_5 seed=2026 (1/1) iters=82\n[OvR-FULL] target_2_6 seed=2026 (1/1) iters=325\n[OvR-FULL] target_2_7 seed=2026 (1/1) iters=8\n[OvR-FULL] target_2_8 seed=2026 (1/1) iters=97\n[OvR-FULL] target_3_1 seed=2026 (1/1) iters=3225\n[OvR-FULL] target_3_2 seed=2026 (1/1) iters=3719\n[OvR-FULL] target_3_3 seed=2026 (1/1) iters=54\n[OvR-FULL] target_3_4 seed=2026 (1/1) iters=127\n[OvR-FULL] target_3_5 seed=2026 (1/1) iters=113\n[OvR-FULL] target_4_1 seed=2026 (1/1) iters=263\n[OvR-FULL] target_5_1 seed=2026 (1/1) iters=248\n[OvR-FULL] target_5_2 seed=2026 (1/1) iters=109\n[OvR-FULL] target_6_1 seed=2026 (1/1) iters=310\n[OvR-FULL] target_6_2 seed=2026 (1/1) iters=321\n[OvR-FULL] target_6_3 seed=2026 (1/1) iters=243\n[OvR-FULL] target_6_4 seed=2026 (1/1) iters=565\n[OvR-FULL] target_6_5 seed=2026 (1/1) iters=85\n[OvR-FULL] target_7_1 seed=2026 (1/1) iters=2196\n[OvR-FULL] target_7_2 seed=2026 (1/1) iters=1795\n[OvR-FULL] target_7_3 seed=2026 (1/1) iters=149\n[OvR-FULL] target_8_1 seed=2026 (1/1) iters=5993\n[OvR-FULL] target_8_2 seed=2026 (1/1) iters=2505\n[OvR-FULL] target_8_3 seed=2026 (1/1) iters=1057\n[OvR-FULL] target_9_1 seed=2026 (1/1) iters=167\n[OvR-FULL] target_9_2 seed=2026 (1/1) iters=1259\n[OvR-FULL] target_9_3 seed=2026 (1/1) iters=324\n[OvR-FULL] target_9_4 seed=2026 (1/1) iters=174\n[OvR-FULL] target_9_5 seed=2026 (1/1) iters=259\n[OvR-FULL] target_9_6 seed=2026 (1/1) iters=4889\n[OvR-FULL] target_9_7 seed=2026 (1/1) iters=2676\n[OvR-FULL] target_9_8 seed=2026 (1/1) iters=938\n[OvR-FULL] target_10_1 seed=2026 (1/1) iters=5880\nSaved submission: submission.parquet | shape=(250000, 42)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "id": "2a4420a4-eba3-4b25-8b6b-595d0f8fa155",
   "cell_type": "code",
   "source": "# ============================================================\n# BLOCK 1 (FIXED): Build /kaggle/working/per_target_auc.csv\n# Priority:\n#   1) use OOF (if available in memory or .npy)\n#   2) fallback to blend_weights.csv (holdout_auc / oof_auc)\n#\n# Writes:\n#   /kaggle/working/per_target_auc.csv      (all targets, worst->best)\n#   /kaggle/working/worst_targets_25.txt    (top-25 worst targets)\n# ============================================================\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\n\n# -----------------------------\n# helpers\n# -----------------------------\ndef autodiscover_data_dir():\n    candidates = [\n        \"/kaggle/input/data-fusion-contest-2026\",\n        \"/kaggle/input/datasets/hatab123/data-fusion-contest-2026\",\n    ]\n    for c in candidates:\n        if os.path.exists(os.path.join(c, \"sample_submit.parquet\")) and os.path.exists(os.path.join(c, \"train_target.parquet\")):\n            return c\n    base = \"/kaggle/input\"\n    for root, _, files in os.walk(base):\n        if \"sample_submit.parquet\" in files and \"train_target.parquet\" in files:\n            return root\n    raise FileNotFoundError(\"   sample_submit.parquet + train_target.parquet  /kaggle/input\")\n\ndef safe_auc(y_true, y_score):\n    if np.unique(y_true).size < 2:\n        return np.nan\n    return roc_auc_score(y_true, y_score)\n\ndef rank_pct_1d(x: np.ndarray) -> np.ndarray:\n    x = np.asarray(x)\n    n = x.shape[0]\n    order = np.argsort(x, kind=\"mergesort\")\n    r = np.empty(n, dtype=np.int32)\n    r[order] = np.arange(n, dtype=np.int32)\n    return ((r + 1) / (n + 1)).astype(np.float32)\n\n# -----------------------------\n# paths + schema\n# -----------------------------\nDATA_DIR = autodiscover_data_dir()\nSAMPLE_SUBMIT_PATH = os.path.join(DATA_DIR, \"sample_submit.parquet\")\nTRAIN_TARGET_PATH  = os.path.join(DATA_DIR, \"train_target.parquet\")\n\nsample = pd.read_parquet(SAMPLE_SUBMIT_PATH)\nsubmit_cols = sample.columns.tolist()\npred_cols = [c for c in submit_cols if c != \"customer_id\"]\ntarget_cols = [c.replace(\"predict_\", \"target_\") for c in pred_cols]\n\n# target prevalence (always useful)\ny_df = pd.read_parquet(TRAIN_TARGET_PATH)[[\"customer_id\"] + target_cols].sort_values(\"customer_id\").reset_index(drop=True)\nY = y_df[target_cols].astype(np.uint8).values\npos_rate = Y.mean(axis=0)\n\n# -----------------------------\n# try OOF first\n# -----------------------------\nP = None\noof_source = None\n\n# in-memory candidates\nfor nm in [\"oof\", \"oof_raw\", \"oof_cat\", \"oof_pred\", \"base_oof\", \"stack_oof\"]:\n    if nm in globals():\n        arr = np.asarray(globals()[nm])\n        if arr.ndim == 2 and arr.shape == Y.shape:\n            P = arr\n            oof_source = f\"globals()['{nm}']\"\n            break\n\n# file candidates\nif P is None:\n    for cand in [\n        \"/kaggle/working/oof.npy\",\n        \"/kaggle/working/oof_cat.npy\",\n        \"/kaggle/working/oof_logits.npy\",\n        \"/kaggle/working/stack_oof.npy\",\n    ]:\n        if os.path.exists(cand):\n            arr = np.load(cand)\n            if arr.ndim == 2 and arr.shape == Y.shape:\n                P = arr\n                oof_source = cand\n                break\n\n# -----------------------------\n# build per_target_auc.csv\n# -----------------------------\nrows = []\n\nif P is not None:\n    # TRUE OOF mode (best)\n    auc_rank = np.array([safe_auc(Y[:, j], rank_pct_1d(P[:, j])) for j in range(Y.shape[1])], dtype=np.float64)\n    source_name = f\"OOF ranks ({oof_source})\"\n    n_eval_rows = int(Y.shape[0])\n\n    df_full = pd.DataFrame({\n        \"target\": target_cols,\n        \"pos_rate\": pos_rate,\n        \"auc\": auc_rank,        # for old patch blocks expecting column \"auc\"\n        \"auc_rank\": auc_rank,   # for new blocks\n        \"metric_source\": source_name,\n        \"n_eval_rows\": n_eval_rows,\n    })\n\nelse:\n    # FALLBACK: use holdout metrics from blend_weights.csv (from your FULL-TRAIN block)\n    bw_candidates = [\n        \"/kaggle/working/blend_weights.csv\",\n        \"blend_weights.csv\",\n    ]\n    bw_path = None\n    for p in bw_candidates:\n        if os.path.exists(p):\n            bw_path = p\n            break\n\n    if bw_path is None:\n        raise ValueError(\n            \"  OOF    blend_weights.csv.\\n\"\n            \"   :\\n\"\n            \"1)  OOF (oof.npy), \\n\"\n            \"2)  FULL-TRAIN   holdout (  blend_weights.csv).\"\n        )\n\n    bw = pd.read_csv(bw_path)\n\n    # detect metric column\n    metric_col = None\n    for c in [\"holdout_auc\", \"oof_auc\", \"auc\", \"auc_rank\"]:\n        if c in bw.columns:\n            metric_col = c\n            break\n\n    if metric_col is None or \"target\" not in bw.columns:\n        raise ValueError(f\" {bw_path}    ( target + holdout_auc/oof_auc/auc).\")\n\n    # merge with all targets to ensure all 41 are present\n    df_full = pd.DataFrame({\n        \"target\": target_cols,\n        \"pos_rate\": pos_rate,\n    }).merge(\n        bw[[\"target\", metric_col]].rename(columns={metric_col: \"auc\"}),\n        on=\"target\",\n        how=\"left\"\n    )\n\n    # duplicate for compatibility\n    df_full[\"auc_rank\"] = df_full[\"auc\"]\n    df_full[\"metric_source\"] = f\"{os.path.basename(bw_path)}::{metric_col} (HOLDOUT proxy)\"\n    # approximate eval rows from your config (5% of 750k) if not available\n    df_full[\"n_eval_rows\"] = int(round(len(Y) * 0.05))\n\n# ranking / gaps\ndf_full[\"rank_worst_to_best\"] = df_full[\"auc\"].rank(method=\"min\", ascending=True).astype(\"Int64\")\ndf_full[\"gap_to_0_82\"] = 0.82 - df_full[\"auc\"]\ndf_full[\"gap_to_0_85\"] = 0.85 - df_full[\"auc\"]\n\n# sort worst -> best\ndf_full = df_full.sort_values([\"auc\", \"target\"], ascending=[True, True]).reset_index(drop=True)\n\n# save\nout_csv = \"/kaggle/working/per_target_auc.csv\"\nout_txt = \"/kaggle/working/worst_targets_25.txt\"\n\ndf_full.to_csv(out_csv, index=False)\nworst25 = df_full.head(25)[\"target\"].tolist()\nwith open(out_txt, \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(worst25))\n\n# print summary\nprint(\"Saved:\", out_csv)\nprint(\"Saved:\", out_txt)\nprint(\"Metric source:\", df_full[\"metric_source\"].iloc[0])\n\nvalid_auc = df_full[\"auc\"].dropna()\nif len(valid_auc):\n    print(\"Macro (mean over available targets):\", float(valid_auc.mean()))\nelse:\n    print(\"No valid AUC values found.\")\n\nprint(\"\\nTOP-10 worst:\")\nprint(df_full.head(10)[[\"target\", \"pos_rate\", \"auc\", \"gap_to_0_82\", \"gap_to_0_85\"]].to_string(index=False))\n\nprint(\"\\nTOP-10 best:\")\nprint(df_full.tail(10)[[\"target\", \"pos_rate\", \"auc\"]].to_string(index=False))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-24T14:11:46.691963Z",
     "iopub.execute_input": "2026-02-24T14:11:46.692106Z",
     "iopub.status.idle": "2026-02-24T14:11:47.078887Z",
     "shell.execute_reply.started": "2026-02-24T14:11:46.692092Z",
     "shell.execute_reply": "2026-02-24T14:11:47.078471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Saved: /kaggle/working/per_target_auc.csv\nSaved: /kaggle/working/worst_targets_25.txt\nMetric source: blend_weights.csv::holdout_auc (HOLDOUT proxy)\nMacro (mean over available targets): 0.8418818664615445\n\nTOP-10 worst:\n     target  pos_rate      auc  gap_to_0_82  gap_to_0_85\n target_9_3  0.018679 0.689375     0.130625     0.160625\n target_9_6  0.223072 0.700661     0.119339     0.149339\n target_3_1  0.098373 0.706182     0.113818     0.143818\n target_5_2  0.002559 0.729861     0.090139     0.120139\n target_6_2  0.007388 0.730065     0.089935     0.119935\n target_6_1  0.008831 0.746307     0.073693     0.103693\n target_3_3  0.001187 0.749762     0.070238     0.100238\n target_2_4  0.007569 0.760313     0.059687     0.089687\n target_5_1  0.009344 0.763876     0.056124     0.086124\ntarget_10_1  0.315052 0.766047     0.053953     0.083953\n\nTOP-10 best:\n    target  pos_rate      auc\ntarget_3_2  0.097409 0.914935\ntarget_1_1  0.010396 0.916774\ntarget_9_4  0.001940 0.925289\ntarget_2_2  0.025345 0.939998\ntarget_9_8  0.010433 0.944246\ntarget_3_4  0.001952 0.946967\ntarget_6_5  0.000559 0.963442\ntarget_3_5  0.001417 0.972399\ntarget_8_1  0.102496 0.984054\ntarget_2_8  0.000111 0.999320\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 2
  },
  {
   "id": "7efaf1d6-94c8-4e0e-b8ba-aeadf8dccc9a",
   "cell_type": "code",
   "source": "# ============================================================\n# BLOCK 2 (FIXED + SAFE): Patch worst-25 targets on GPU and continue notebook on error\n# - reads:  /kaggle/working/per_target_auc.csv\n# - base:   latest patched submit or submission.parquet\n# - writes: /kaggle/working/submit_patched25.parquet\n#           /kaggle/working/patch25_report.csv\n#           /kaggle/working/patch25_error.log (if error)\n#\n# :\n# -     globals()  X/X_test/y_mat/cat_features:\n#       .\n# -  OOF ,  :   conservative  (fixed weight).\n# -     try/except,    .\n# ============================================================\n\ntry:\n    import os, gc, time, warnings, traceback\n    warnings.filterwarnings(\"ignore\")\n\n    import numpy as np\n    import pandas as pd\n    from catboost import CatBoostClassifier, Pool\n    from sklearn.model_selection import StratifiedShuffleSplit\n    from sklearn.metrics import roc_auc_score\n\n    try:\n        from tqdm.auto import tqdm\n    except Exception:\n        def tqdm(x=None, **kwargs): return x if x is not None else None\n\n    # ----------------------------\n    # CONFIG\n    # ----------------------------\n    SPLIT_SEED = 42                 # int ()\n    PATCH_SEEDS = [42, 1337]        #  seed'  bagging \n    VAL_SIZE = 0.05\n    TOP_N = 25\n\n    #  OOF :     gain >= MIN_GAIN\n    MIN_GAIN = 0.0015\n    W_GRID = [0.0, 0.3, 0.6, 0.8, 1.0]\n\n    #  OOF :    \n    FIXED_W_NO_OOF = 0.30\n\n    # GPU caps ( /)\n    CAP_RARE = 1200   # pos_rate < 0.5%\n    CAP_MID  = 1800   # 0.5%..5%\n    CAP_COM  = 3200   # >=5% ( )\n    OD_RARE, OD_MID, OD_COM = 120, 150, 220\n\n    # I/O\n    AUC_FILE = \"/kaggle/working/per_target_auc.csv\"\n    OUT_PATH = \"/kaggle/working/submit_patched25.parquet\"\n    REPORT_PATH = \"/kaggle/working/patch25_report.csv\"\n    ERR_LOG_PATH = \"/kaggle/working/patch25_error.log\"\n\n    assert os.path.exists(AUC_FILE), \"  BLOCK 1 -> /kaggle/working/per_target_auc.csv\"\n\n    # ----------------------------\n    # Helpers\n    # ----------------------------\n    def autodiscover_data_dir():\n        candidates = [\n            \"/kaggle/input/data-fusion-contest-2026\",\n            \"/kaggle/input/datasets/hatab123/data-fusion-contest-2026\",\n        ]\n        for c in candidates:\n            if os.path.exists(os.path.join(c, \"sample_submit.parquet\")):\n                return c\n        for root, _, files in os.walk(\"/kaggle/input\"):\n            if \"sample_submit.parquet\" in files:\n                return root\n        raise FileNotFoundError(\"   sample_submit.parquet  /kaggle/input\")\n\n    def safe_auc(y_true, y_score):\n        y_true = np.asarray(y_true)\n        if np.unique(y_true).size < 2:\n            return np.nan\n        return float(roc_auc_score(y_true, y_score))\n\n    def rank_pct_1d(x):\n        x = np.asarray(x)\n        n = x.shape[0]\n        order = np.argsort(x, kind=\"mergesort\")\n        r = np.empty(n, dtype=np.int32)\n        r[order] = np.arange(n, dtype=np.int32)\n        return ((r + 1) / (n + 1)).astype(np.float32)\n\n    def logit_from_rank(r):\n        r = np.clip(r, 1e-6, 1 - 1e-6)\n        return np.log(r / (1 - r)).astype(np.float32)\n\n    def rank_blend_logits(base_scores, patch_scores, w):\n        rb = rank_pct_1d(np.asarray(base_scores, dtype=np.float32))\n        rp = rank_pct_1d(np.asarray(patch_scores, dtype=np.float32))\n        r = (1.0 - w) * rb + w * rp\n        return logit_from_rank(r)\n\n    def gpu_params(seed, group, spw):\n        p = dict(\n            loss_function=\"Logloss\",\n            eval_metric=\"Logloss\",\n            random_strength=1.0,\n            bootstrap_type=\"Bernoulli\",\n            subsample=0.88,\n            allow_writing_files=False,\n            task_type=\"GPU\",\n            devices=\"0\",\n            verbose=0,\n            random_seed=int(seed),\n            boosting_type=\"Plain\",\n            od_type=\"Iter\",\n        )\n        if group == \"rare\":\n            p.update(iterations=CAP_RARE, depth=7, learning_rate=0.10, l2_leaf_reg=35.0, od_wait=OD_RARE)\n            p[\"scale_pos_weight\"] = float(spw)\n        elif group == \"mid\":\n            p.update(iterations=CAP_MID, depth=8, learning_rate=0.08, l2_leaf_reg=25.0, od_wait=OD_MID)\n            p[\"scale_pos_weight\"] = float(spw)\n        else:\n            p.update(iterations=CAP_COM, depth=10, learning_rate=0.05, l2_leaf_reg=12.0, od_wait=OD_COM)\n        return p\n\n    def load_oof_if_any():\n        # 1) memory\n        for name in [\"oof\", \"oof_raw\", \"oof_cat\", \"base_oof\", \"stack_oof\"]:\n            if name in globals():\n                try:\n                    arr = np.asarray(globals()[name])\n                    if arr.ndim == 2:\n                        return arr, f\"globals()['{name}']\"\n                except Exception:\n                    pass\n        # 2) disk\n        for cand in [\n            \"/kaggle/working/oof.npy\",\n            \"/kaggle/working/oof_cat.npy\",\n            \"/kaggle/working/oof_logits.npy\",\n            \"/kaggle/working/oof_raw.npy\",\n        ]:\n            if os.path.exists(cand):\n                try:\n                    arr = np.load(cand)\n                    return arr, cand\n                except Exception:\n                    pass\n        return None, None\n\n    def pick_base_submit():\n        base_candidates = [\n            \"/kaggle/working/submit_patched20.parquet\",\n            \"/kaggle/working/submit_patched15.parquet\",\n            \"/kaggle/working/submit_patched.parquet\",\n            \"/kaggle/working/submit.parquet\",\n            \"/kaggle/working/submission.parquet\",\n        ]\n        return next((p for p in base_candidates if os.path.exists(p)), None)\n\n    def save_error_fallback(msg, sample_submit_path=None):\n        # report\n        pd.DataFrame([{\n            \"target\": \"__ALL__\",\n            \"pred_col\": \"__ALL__\",\n            \"pos_rate\": np.nan,\n            \"group\": \"n/a\",\n            \"mode\": \"ERROR_FALLBACK\",\n            \"base_auc_val\": np.nan,\n            \"best_auc_val\": np.nan,\n            \"gain\": np.nan,\n            \"best_w\": np.nan,\n            \"mins\": 0.0,\n            \"status\": \"ERROR_SKIP\",\n            \"reason\": str(msg)[:1000],\n        }]).to_csv(REPORT_PATH, index=False)\n\n        base_path = pick_base_submit()\n        if base_path is not None:\n            sub = pd.read_parquet(base_path)\n            pred_cols_local = [c for c in sub.columns if c.startswith(\"predict_\")]\n            for c in pred_cols_local:\n                sub[c] = sub[c].astype(np.float64)\n            sub.to_parquet(OUT_PATH, index=False)\n            print(f\"[FALLBACK] Saved unchanged submit -> {OUT_PATH} (from {base_path})\")\n        else:\n            #         \n            print(\"[FALLBACK] Base submit not found, saved only report.\")\n\n        print(f\"[FALLBACK] Saved report -> {REPORT_PATH}\")\n\n    def ensure_preprocessed_matrices(data_dir, target_cols):\n        \"\"\"\n         X, X_test, Y, cat_features, test_df, submit_cols, pred_cols, target_cols\n        1)    globals\n        2)     \n        \"\"\"\n        # ----- try globals first -----\n        have = all(v in globals() for v in [\"X\", \"X_test\", \"y_mat\", \"cat_features\"])\n        if have:\n            X = globals()[\"X\"]\n            X_test = globals()[\"X_test\"]\n            Y = np.asarray(globals()[\"y_mat\"])\n            cat_features = globals()[\"cat_features\"]\n            # sanity\n            if Y.shape[1] == len(target_cols):\n                print(\"Using X/X_test/y_mat/cat_features from globals().\")\n                return X, X_test, Y, cat_features\n            else:\n                print(\"Globals found but target dimension mismatch -> rebuilding matrices...\")\n\n        # ----- build from parquet -----\n        print(\"Building X/X_test/y_mat/cat_features from parquet (no globals found)...\")\n        t0 = time.time()\n\n        train_main_path  = os.path.join(data_dir, \"train_main_features.parquet\")\n        train_extra_path = os.path.join(data_dir, \"train_extra_features.parquet\")\n        test_main_path   = os.path.join(data_dir, \"test_main_features.parquet\")\n        test_extra_path  = os.path.join(data_dir, \"test_extra_features.parquet\")\n        train_tgt_path   = os.path.join(data_dir, \"train_target.parquet\")\n\n        train_main = pd.read_parquet(train_main_path)\n        train_extra = pd.read_parquet(train_extra_path)\n        test_main = pd.read_parquet(test_main_path)\n        test_extra = pd.read_parquet(test_extra_path)\n\n        # merge by customer_id (safe)\n        train_df = train_main.merge(train_extra, on=\"customer_id\", how=\"left\")\n        test_df = test_main.merge(test_extra, on=\"customer_id\", how=\"left\")\n        del train_main, train_extra, test_main, test_extra\n        gc.collect()\n\n        y_df = pd.read_parquet(train_tgt_path)[[\"customer_id\"] + target_cols].copy()\n\n        # align by customer_id\n        train_df = train_df.sort_values(\"customer_id\").reset_index(drop=True)\n        test_df = test_df.sort_values(\"customer_id\").reset_index(drop=True)\n        y_df = y_df.sort_values(\"customer_id\").reset_index(drop=True)\n\n        if not np.array_equal(train_df[\"customer_id\"].values, y_df[\"customer_id\"].values):\n            #       \n            train_df = train_df.merge(y_df[[\"customer_id\"]], on=\"customer_id\", how=\"inner\")\n            train_df = train_df.sort_values(\"customer_id\").reset_index(drop=True)\n            y_df = y_df.sort_values(\"customer_id\").reset_index(drop=True)\n            assert np.array_equal(train_df[\"customer_id\"].values, y_df[\"customer_id\"].values), \\\n                \"train features and train_target customer_id mismatch\"\n\n        Y = y_df[target_cols].astype(np.uint8).values\n\n        # Features\n        feature_cols = [c for c in train_df.columns if c != \"customer_id\"]\n        cat_cols = [c for c in feature_cols if c.startswith(\"cat_feature\")]\n        num_cols = [c for c in feature_cols if c not in cat_cols]\n\n        # CatBoost can ingest strings as cats\n        for c in tqdm(cat_cols, desc=\"Patch-prep: categorical stringify\"):\n            train_df[c] = train_df[c].fillna(\"__MISSING__\").astype(str)\n            test_df[c] = test_df[c].fillna(\"__MISSING__\").astype(str)\n\n        # Downcast numerics to float32 (memory)\n        for c in tqdm(num_cols, desc=\"Patch-prep: numeric downcast\"):\n            train_df[c] = pd.to_numeric(train_df[c], errors=\"coerce\").astype(np.float32)\n            test_df[c] = pd.to_numeric(test_df[c], errors=\"coerce\").astype(np.float32)\n\n        X = train_df[feature_cols].copy()\n        X_test = test_df[feature_cols].copy()\n        cat_features = [feature_cols.index(c) for c in cat_cols]\n\n        print(f\"Built matrices in {(time.time()-t0)/60:.1f} min | X={X.shape} X_test={X_test.shape} cats={len(cat_features)}\")\n        return X, X_test, Y, cat_features\n\n    # ----------------------------\n    # Discover data + schema\n    # ----------------------------\n    DATA_DIR = autodiscover_data_dir()\n    sample_path = os.path.join(DATA_DIR, \"sample_submit.parquet\")\n    sample = pd.read_parquet(sample_path)\n\n    submit_cols = sample.columns.tolist()\n    pred_cols = [c for c in submit_cols if c != \"customer_id\"]\n    target_cols = [c.replace(\"predict_\", \"target_\") for c in pred_cols]\n\n    # ----------------------------\n    # Load matrices (globals or build)\n    # ----------------------------\n    X, X_test, Y, cat_features = ensure_preprocessed_matrices(DATA_DIR, target_cols)\n\n    if Y.shape[1] != len(target_cols):\n        raise ValueError(f\"Shape mismatch: y_mat has {Y.shape[1]} targets, sample_submit implies {len(target_cols)}\")\n\n    # ----------------------------\n    # Load OOF if present (optional)\n    # ----------------------------\n    OOF, OOF_SRC = load_oof_if_any()\n    HAS_OOF = isinstance(OOF, np.ndarray) and OOF.shape == Y.shape\n    if HAS_OOF:\n        print(f\"OOF found: {OOF_SRC} | shape={OOF.shape}\")\n    else:\n        print(\"OOF not found (or wrong shape) -> conservative mode (fixed weight, no gain gating).\")\n        OOF = None\n\n    # ----------------------------\n    # Base submission to improve\n    # ----------------------------\n    BASE_SUB_PATH = pick_base_submit()\n    if BASE_SUB_PATH is None:\n        raise FileNotFoundError(\"     /kaggle/working/ (submit*.parquet)\")\n    base_sub = pd.read_parquet(BASE_SUB_PATH)[submit_cols].copy()\n    patched = base_sub.copy()\n    print(\"Base submit:\", BASE_SUB_PATH, patched.shape)\n\n    # ----------------------------\n    # Worst targets from per_target_auc.csv\n    # ----------------------------\n    auc_df = pd.read_csv(AUC_FILE).copy()\n\n    # normalize metric column\n    if \"auc_rank\" not in auc_df.columns:\n        if \"auc\" in auc_df.columns:\n            auc_df = auc_df.rename(columns={\"auc\": \"auc_rank\"})\n        else:\n            raise ValueError(\" per_target_auc.csv   auc_rank/auc\")\n\n    # keep only valid targets\n    auc_df = auc_df[auc_df[\"target\"].isin(target_cols)].copy()\n    if auc_df.empty:\n        raise ValueError(\"per_target_auc.csv    target_* \")\n    auc_df = auc_df.sort_values(\"auc_rank\").reset_index(drop=True)\n\n    targets_to_try = auc_df.head(TOP_N)[\"target\"].tolist()\n    print(f\"Targets to patch (TOP-{TOP_N} worst):\")\n    print(targets_to_try)\n\n    # ----------------------------\n    # Validation split (same logic as before)\n    # ----------------------------\n    y_sum = Y.sum(axis=1)\n    bins = pd.cut(y_sum, bins=[-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 100], labels=False).astype(int)\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_SIZE, random_state=SPLIT_SEED)\n    tr_idx, va_idx = next(sss.split(np.zeros((len(Y), 1)), bins))\n\n    X_tr = X.iloc[tr_idx]\n    X_va = X.iloc[va_idx]\n    pool_test = Pool(X_test, cat_features=cat_features)\n\n    print(f\"Val split: train={len(tr_idx)} val={len(va_idx)} (~{VAL_SIZE*100:.1f}%)\")\n\n    # ----------------------------\n    # Patch loop\n    # ----------------------------\n    report = []\n    applied = 0\n    skipped = 0\n\n    total_steps = len(targets_to_try) * len(PATCH_SEEDS)\n    pbar = tqdm(total=total_steps, desc=\"Patch 25 (GPU, ETA)\", mininterval=1.0)\n\n    for tname in targets_to_try:\n        j = target_cols.index(tname)\n        pred_col = tname.replace(\"target_\", \"predict_\")\n\n        row = auc_df.loc[auc_df[\"target\"] == tname].iloc[0]\n        pr = float(row[\"pos_rate\"]) if \"pos_rate\" in auc_df.columns else float(Y[:, j].mean())\n\n        # prevalence group\n        if pr < 0.005:\n            group = \"rare\"\n        elif pr < 0.05:\n            group = \"mid\"\n        else:\n            group = \"common\"\n\n        y = Y[:, j].astype(np.uint8)\n        y_tr = y[tr_idx]\n        y_va = y[va_idx]\n\n        if np.unique(y_tr).size < 2 or np.unique(y_va).size < 2:\n            skipped += 1\n            pbar.update(len(PATCH_SEEDS))\n            report.append({\n                \"target\": tname, \"pred_col\": pred_col, \"pos_rate\": pr, \"group\": group,\n                \"mode\": \"SKIP_DEGENERATE\",\n                \"base_auc_val\": np.nan, \"best_auc_val\": np.nan, \"gain\": np.nan,\n                \"best_w\": np.nan, \"mins\": 0.0, \"status\": \"SKIP_DEGENERATE\"\n            })\n            continue\n\n        # Safe base validation metric only if OOF exists\n        if HAS_OOF:\n            base_val = OOF[va_idx, j].astype(np.float32)\n            base_auc = safe_auc(y_va, rank_pct_1d(base_val))\n        else:\n            base_val = None\n            base_auc = np.nan\n\n        # class weights\n        if group == \"common\":\n            spw = None\n        else:\n            pos = float(y_tr.sum())\n            neg = float(len(y_tr) - pos)\n            spw_cap = 6.0 if group == \"rare\" else 12.0\n            spw = min(neg / max(1.0, pos), spw_cap)\n\n        if hasattr(tqdm, \"write\"):\n            tqdm.write(f\"START {tname} | group={group} | pos_rate={pr:.4%} | spw={spw}\")\n\n        t0 = time.time()\n        pred_patch_val = np.zeros(len(va_idx), dtype=np.float32)\n        pred_patch_test = np.zeros(len(X_test), dtype=np.float32)\n\n        # Pools once per target\n        tr_pool = Pool(X_tr, label=y_tr, cat_features=cat_features)\n        va_pool = Pool(X_va, label=y_va, cat_features=cat_features)\n\n        for seed in PATCH_SEEDS:\n            model = CatBoostClassifier(**gpu_params(seed, group, spw))\n            model.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n\n            pred_patch_val += (\n                model.predict(va_pool, prediction_type=\"RawFormulaVal\").reshape(-1).astype(np.float32)\n                / len(PATCH_SEEDS)\n            )\n            pred_patch_test += (\n                model.predict(pool_test, prediction_type=\"RawFormulaVal\").reshape(-1).astype(np.float32)\n                / len(PATCH_SEEDS)\n            )\n\n            del model\n            gc.collect()\n            pbar.update(1)\n\n        del tr_pool, va_pool\n        gc.collect()\n\n        # Weight selection\n        if HAS_OOF and np.isfinite(base_auc):\n            best_w, best_auc = 0.0, base_auc\n            for w in W_GRID:\n                rblend = (1.0 - w) * rank_pct_1d(base_val) + w * rank_pct_1d(pred_patch_val)\n                a = safe_auc(y_va, rblend)\n                if np.isfinite(a) and a > best_auc:\n                    best_auc, best_w = float(a), float(w)\n\n            gain = float(best_auc - base_auc)\n            apply_patch = (best_w > 0) and (gain >= MIN_GAIN)\n            mode = \"OOF_TUNED\"\n        else:\n            best_w = float(FIXED_W_NO_OOF)\n            best_auc = safe_auc(y_va, rank_pct_1d(pred_patch_val))  # info only\n            gain = np.nan\n            apply_patch = best_w > 0\n            mode = \"NO_OOF_FIXED\"\n\n        elapsed_min = (time.time() - t0) / 60.0\n\n        if apply_patch:\n            base_scores_test = patched[pred_col].to_numpy(dtype=np.float32)\n            patched[pred_col] = rank_blend_logits(base_scores_test, pred_patch_test, w=best_w).astype(np.float64)\n            applied += 1\n            status = \"APPLY\"\n        else:\n            skipped += 1\n            status = \"SKIP_LOW_GAIN\"\n\n        if hasattr(tqdm, \"write\"):\n            tqdm.write(\n                f\"DONE  {tname} | status={status} | mode={mode} | w={best_w:.2f} | \"\n                f\"base_auc={base_auc if np.isfinite(base_auc) else np.nan:.4f} | \"\n                f\"best_auc={best_auc if np.isfinite(best_auc) else np.nan:.4f} | \"\n                f\"mins={elapsed_min:.1f}\"\n            )\n\n        report.append({\n            \"target\": tname,\n            \"pred_col\": pred_col,\n            \"pos_rate\": pr,\n            \"group\": group,\n            \"mode\": mode,\n            \"base_auc_val\": float(base_auc) if np.isfinite(base_auc) else np.nan,\n            \"best_auc_val\": float(best_auc) if np.isfinite(best_auc) else np.nan,\n            \"gain\": float(gain) if np.isfinite(gain) else np.nan,\n            \"best_w\": float(best_w),\n            \"mins\": float(elapsed_min),\n            \"status\": status,\n        })\n\n    if pbar is not None:\n        pbar.close()\n\n    # ----------------------------\n    # Save outputs\n    # ----------------------------\n    rep_df = pd.DataFrame(report)\n\n    if len(rep_df):\n        status_order = {\"APPLY\": 0, \"SKIP_LOW_GAIN\": 1, \"SKIP_DEGENERATE\": 2}\n        rep_df[\"_order\"] = rep_df[\"status\"].map(status_order).fillna(99).astype(int)\n        rep_df = rep_df.sort_values([\"_order\", \"gain\"], ascending=[True, False]).drop(columns=[\"_order\"])\n\n    rep_df.to_csv(REPORT_PATH, index=False)\n\n    patched = patched[submit_cols].copy()\n    for c in pred_cols:\n        patched[c] = patched[c].astype(np.float64)\n    patched.to_parquet(OUT_PATH, index=False)\n\n    print(\"\\nApplied:\", applied, \"| Skipped:\", skipped)\n    print(\"Saved:\", OUT_PATH, patched.shape)\n    print(\"Saved report:\", REPORT_PATH)\n\n    if len(rep_df):\n        print(\"\\nTop applied patches:\")\n        show_cols = [c for c in [\"target\",\"group\",\"mode\",\"best_w\",\"base_auc_val\",\"best_auc_val\",\"gain\",\"mins\"] if c in rep_df.columns]\n        print(rep_df[rep_df[\"status\"] == \"APPLY\"].head(10)[show_cols].to_string(index=False))\n\nexcept Exception as e:\n    # -------- SAFE fallback so next blocks still run --------\n    import traceback, os\n    err_text = f\"{type(e).__name__}: {e}\"\n    tb = traceback.format_exc()\n\n    try:\n        with open(\"/kaggle/working/patch25_error.log\", \"w\", encoding=\"utf-8\") as f:\n            f.write(tb)\n    except Exception:\n        pass\n\n    print(\"\\n[PATCH25 SAFE MODE]  ,    .\")\n    print(\"[PATCH25 SAFE MODE] :\", err_text)\n    print(\"[PATCH25 SAFE MODE]    /kaggle/working/patch25_error.log\")\n\n    # fallback report + fallback submit (copy latest available)\n    try:\n        import numpy as np\n        import pandas as pd\n\n        pd.DataFrame([{\n            \"target\": \"__ALL__\",\n            \"pred_col\": \"__ALL__\",\n            \"pos_rate\": np.nan,\n            \"group\": \"n/a\",\n            \"mode\": \"ERROR_FALLBACK\",\n            \"base_auc_val\": np.nan,\n            \"best_auc_val\": np.nan,\n            \"gain\": np.nan,\n            \"best_w\": np.nan,\n            \"mins\": 0.0,\n            \"status\": \"ERROR_SKIP\",\n            \"reason\": err_text[:1000],\n        }]).to_csv(\"/kaggle/working/patch25_report.csv\", index=False)\n\n        base_candidates = [\n            \"/kaggle/working/submit_patched20.parquet\",\n            \"/kaggle/working/submit_patched15.parquet\",\n            \"/kaggle/working/submit_patched.parquet\",\n            \"/kaggle/working/submit.parquet\",\n            \"/kaggle/working/submission.parquet\",\n        ]\n        base_path = next((p for p in base_candidates if os.path.exists(p)), None)\n        if base_path is not None:\n            sub = pd.read_parquet(base_path)\n            pred_cols_local = [c for c in sub.columns if c.startswith(\"predict_\")]\n            for c in pred_cols_local:\n                sub[c] = sub[c].astype(np.float64)\n            sub.to_parquet(\"/kaggle/working/submit_patched25.parquet\", index=False)\n            print(f\"[PATCH25 SAFE MODE] Saved fallback submit -> /kaggle/working/submit_patched25.parquet (from {base_path})\")\n        else:\n            print(\"[PATCH25 SAFE MODE]    ,   report.\")\n    except Exception as e2:\n        print(\"[PATCH25 SAFE MODE]    fallback outputs:\", repr(e2))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-24T14:15:40.028897Z",
     "iopub.execute_input": "2026-02-24T14:15:40.029128Z",
     "iopub.status.idle": "2026-02-24T16:03:43.959779Z",
     "shell.execute_reply.started": "2026-02-24T14:15:40.029110Z",
     "shell.execute_reply": "2026-02-24T16:03:43.959370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Building X/X_test/y_mat/cat_features from parquet (no globals found)...\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Patch-prep: categorical stringify:   0%|          | 0/67 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd2ed898c92646ffb7002faadf057801"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Patch-prep: numeric downcast:   0%|          | 0/2373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d708e24b4b54a8bbfb87b1ac2acbc15"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Built matrices in 1.3 min | X=(750000, 2440) X_test=(250000, 2440) cats=67\nOOF not found (or wrong shape) -> conservative mode (fixed weight, no gain gating).\nBase submit: /kaggle/working/submission.parquet (250000, 42)\nTargets to patch (TOP-25 worst):\n['target_9_3', 'target_9_6', 'target_3_1', 'target_5_2', 'target_6_2', 'target_6_1', 'target_3_3', 'target_2_4', 'target_5_1', 'target_10_1', 'target_9_1', 'target_6_3', 'target_9_7', 'target_2_6', 'target_2_5', 'target_1_2', 'target_7_1', 'target_7_3', 'target_2_1', 'target_2_3', 'target_9_2', 'target_1_4', 'target_4_1', 'target_7_2', 'target_9_5']\nVal split: train=712500 val=37500 (~5.0%)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Patch 25 (GPU, ETA):   0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c96e4eed92914ed287b3fb8616869d50"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "START target_9_3 | group=mid | pos_rate=1.8679% | spw=12.0\nDONE  target_9_3 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.6808 | mins=1.5\nSTART target_9_6 | group=common | pos_rate=22.3072% | spw=None\nDONE  target_9_6 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.6981 | mins=13.2\nSTART target_3_1 | group=common | pos_rate=9.8373% | spw=None\nDONE  target_3_1 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7051 | mins=11.0\nSTART target_5_2 | group=rare | pos_rate=0.2559% | spw=6.0\nDONE  target_5_2 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7180 | mins=1.3\nSTART target_6_2 | group=mid | pos_rate=0.7388% | spw=12.0\nDONE  target_6_2 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7133 | mins=1.9\nSTART target_6_1 | group=mid | pos_rate=0.8831% | spw=12.0\nDONE  target_6_1 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7411 | mins=1.6\nSTART target_3_3 | group=rare | pos_rate=0.1187% | spw=6.0\nDONE  target_3_3 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7495 | mins=2.1\nSTART target_2_4 | group=mid | pos_rate=0.7569% | spw=12.0\nDONE  target_2_4 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7503 | mins=1.8\nSTART target_5_1 | group=mid | pos_rate=0.9344% | spw=12.0\nDONE  target_5_1 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7556 | mins=1.5\nSTART target_10_1 | group=common | pos_rate=31.5052% | spw=None\nDONE  target_10_1 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7651 | mins=15.5\nSTART target_9_1 | group=rare | pos_rate=0.3635% | spw=6.0\nDONE  target_9_1 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7759 | mins=1.5\nSTART target_6_3 | group=mid | pos_rate=0.5805% | spw=12.0\nDONE  target_6_3 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7711 | mins=1.7\nSTART target_9_7 | group=common | pos_rate=7.7248% | spw=None\nDONE  target_9_7 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7776 | mins=13.3\nSTART target_2_6 | group=rare | pos_rate=0.4407% | spw=6.0\nDONE  target_2_6 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7579 | mins=1.9\nSTART target_2_5 | group=rare | pos_rate=0.1895% | spw=6.0\nDONE  target_2_5 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7459 | mins=3.1\nSTART target_1_2 | group=rare | pos_rate=0.3425% | spw=6.0\nDONE  target_1_2 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.8143 | mins=2.3\nSTART target_7_1 | group=common | pos_rate=6.2500% | spw=None\nDONE  target_7_1 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.8174 | mins=15.6\nSTART target_7_3 | group=rare | pos_rate=0.4245% | spw=6.0\nDONE  target_7_3 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.7962 | mins=2.3\nSTART target_2_1 | group=mid | pos_rate=0.7088% | spw=12.0\nDONE  target_2_1 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.8381 | mins=1.7\nSTART target_2_3 | group=rare | pos_rate=0.1388% | spw=6.0\nDONE  target_2_3 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.8302 | mins=1.5\nSTART target_9_2 | group=mid | pos_rate=3.6449% | spw=12.0\nDONE  target_9_2 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.8461 | mins=2.5\nSTART target_1_4 | group=mid | pos_rate=2.3429% | spw=12.0\nDONE  target_1_4 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.8611 | mins=2.1\nSTART target_4_1 | group=mid | pos_rate=0.8129% | spw=12.0\nDONE  target_4_1 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.8602 | mins=1.6\nSTART target_7_2 | group=mid | pos_rate=2.7672% | spw=12.0\nDONE  target_7_2 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.8697 | mins=2.6\nSTART target_9_5 | group=mid | pos_rate=0.6583% | spw=12.0\nDONE  target_9_5 | status=APPLY | mode=NO_OOF_FIXED | w=0.30 | base_auc=nan | best_auc=0.8698 | mins=1.4\n\nApplied: 25 | Skipped: 0\nSaved: /kaggle/working/submit_patched25.parquet (250000, 42)\nSaved report: /kaggle/working/patch25_report.csv\n\nTop applied patches:\n     target  group         mode  best_w  base_auc_val  best_auc_val  gain      mins\n target_9_3    mid NO_OOF_FIXED     0.3           NaN      0.680832   NaN  1.459856\n target_9_6 common NO_OOF_FIXED     0.3           NaN      0.698050   NaN 13.192440\n target_3_1 common NO_OOF_FIXED     0.3           NaN      0.705066   NaN 11.011315\n target_5_2   rare NO_OOF_FIXED     0.3           NaN      0.717996   NaN  1.278643\n target_6_2    mid NO_OOF_FIXED     0.3           NaN      0.713349   NaN  1.878160\n target_6_1    mid NO_OOF_FIXED     0.3           NaN      0.741135   NaN  1.578472\n target_3_3   rare NO_OOF_FIXED     0.3           NaN      0.749451   NaN  2.107607\n target_2_4    mid NO_OOF_FIXED     0.3           NaN      0.750348   NaN  1.751844\n target_5_1    mid NO_OOF_FIXED     0.3           NaN      0.755645   NaN  1.545504\ntarget_10_1 common NO_OOF_FIXED     0.3           NaN      0.765063   NaN 15.492265\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 6
  },
  {
   "id": "536ec737-bfe5-449d-bef3-a89fea1fdf6c",
   "cell_type": "code",
   "source": "# ============================================================\n# BLOCK 3 (FIXED + SAFE): Second patch pass for worst-30 targets (GPU)\n# - reads:  /kaggle/working/per_target_auc.csv\n# - base:   prefer /kaggle/working/submit_patched25.parquet (then fallback)\n# - writes: /kaggle/working/submit_patched30.parquet\n#           /kaggle/working/patch30_report.csv\n#           /kaggle/working/patch30_error.log (if error)\n#\n# :\n# -     globals()  X/X_test/y_mat/cat_features:  .\n# -  OOF ,  :   conservative  (fixed weight).\n# -    try/except,    .\n# -         (re-patch) + .\n#      \"\"  patch25   EXCLUDE_ALREADY_APPLIED_FROM_PATCH25=True\n# ============================================================\n\ntry:\n    import os, gc, time, warnings, traceback\n    warnings.filterwarnings(\"ignore\")\n\n    import numpy as np\n    import pandas as pd\n    from catboost import CatBoostClassifier, Pool\n    from sklearn.model_selection import StratifiedShuffleSplit\n    from sklearn.metrics import roc_auc_score\n\n    try:\n        from tqdm.auto import tqdm\n    except Exception:\n        class _TQDMStub:\n            def __init__(self, total=None, desc=None, mininterval=1.0): self.total = total\n            def update(self, n=1): pass\n            def close(self): pass\n            @staticmethod\n            def write(x): print(x)\n        def tqdm(*args, **kwargs):  # noqa\n            if len(args) == 0 and (\"total\" in kwargs or \"desc\" in kwargs):\n                return _TQDMStub(**kwargs)\n            return args[0] if args else _TQDMStub(**kwargs)\n\n    # ----------------------------\n    # CONFIG\n    # ----------------------------\n    SPLIT_SEED = 2026\n    PATCH_SEEDS = [42, 1337, 7777]         # 2 seeds =   \n    VAL_SIZE = 0.05\n    TOP_N = 30\n\n    #        patch25  -> True\n    EXCLUDE_ALREADY_APPLIED_FROM_PATCH25 = False\n    PATCH25_REPORT_PATH = \"/kaggle/working/patch25_report.csv\"\n\n    #  OOF :     gain >= MIN_GAIN\n    MIN_GAIN = 0.0010\n    W_GRID = [0.0, 0.15, 0.30, 0.45, 0.60]\n\n    #  OOF :   (2-   )\n    FIXED_W_NO_OOF_RARE = 0.20\n    FIXED_W_NO_OOF_MID = 0.20\n    FIXED_W_NO_OOF_COM = 0.15\n\n    # GPU caps (2- :    )\n    CAP_RARE = 1000   # pos_rate < 0.5%\n    CAP_MID  = 1500   # 0.5%..5%\n    CAP_COM  = 2600   # >=5%\n    OD_RARE, OD_MID, OD_COM = 100, 120, 180\n\n    # I/O\n    AUC_FILE = \"/kaggle/working/per_target_auc.csv\"\n    OUT_PATH = \"/kaggle/working/submit_patched30.parquet\"\n    REPORT_PATH = \"/kaggle/working/patch30_report.csv\"\n    ERR_LOG_PATH = \"/kaggle/working/patch30_error.log\"\n\n    assert os.path.exists(AUC_FILE), \"  BLOCK 1 -> /kaggle/working/per_target_auc.csv\"\n\n    # ----------------------------\n    # Helpers\n    # ----------------------------\n    def autodiscover_data_dir():\n        candidates = [\n            \"/kaggle/input/data-fusion-contest-2026\",\n            \"/kaggle/input/datasets/hatab123/data-fusion-contest-2026\",\n        ]\n        for c in candidates:\n            if os.path.exists(os.path.join(c, \"sample_submit.parquet\")):\n                return c\n        for root, _, files in os.walk(\"/kaggle/input\"):\n            if \"sample_submit.parquet\" in files:\n                return root\n        raise FileNotFoundError(\"   sample_submit.parquet  /kaggle/input\")\n\n    def safe_auc(y_true, y_score):\n        y_true = np.asarray(y_true)\n        if np.unique(y_true).size < 2:\n            return np.nan\n        return float(roc_auc_score(y_true, y_score))\n\n    def rank_pct_1d(x):\n        x = np.asarray(x)\n        n = x.shape[0]\n        order = np.argsort(x, kind=\"mergesort\")\n        r = np.empty(n, dtype=np.int32)\n        r[order] = np.arange(n, dtype=np.int32)\n        return ((r + 1) / (n + 1)).astype(np.float32)\n\n    def logit_from_rank(r):\n        r = np.clip(r, 1e-6, 1 - 1e-6)\n        return np.log(r / (1 - r)).astype(np.float32)\n\n    def rank_blend_logits(base_scores, patch_scores, w):\n        rb = rank_pct_1d(np.asarray(base_scores, dtype=np.float32))\n        rp = rank_pct_1d(np.asarray(patch_scores, dtype=np.float32))\n        r = (1.0 - w) * rb + w * rp\n        return logit_from_rank(r)\n\n    def gpu_params(seed, group, spw):\n        p = dict(\n            loss_function=\"Logloss\",\n            eval_metric=\"Logloss\",\n            random_strength=1.0,\n            bootstrap_type=\"Bernoulli\",\n            subsample=0.88,\n            allow_writing_files=False,\n            task_type=\"GPU\",\n            devices=\"0\",\n            verbose=0,\n            random_seed=int(seed),\n            boosting_type=\"Plain\",\n            od_type=\"Iter\",\n        )\n        if group == \"rare\":\n            p.update(iterations=CAP_RARE, depth=7, learning_rate=0.10, l2_leaf_reg=35.0, od_wait=OD_RARE)\n            p[\"scale_pos_weight\"] = float(spw)\n        elif group == \"mid\":\n            p.update(iterations=CAP_MID, depth=8, learning_rate=0.08, l2_leaf_reg=25.0, od_wait=OD_MID)\n            p[\"scale_pos_weight\"] = float(spw)\n        else:\n            p.update(iterations=CAP_COM, depth=9, learning_rate=0.055, l2_leaf_reg=12.0, od_wait=OD_COM)\n        return p\n\n    def load_oof_if_any():\n        # memory\n        for name in [\"oof\", \"oof_raw\", \"oof_cat\", \"base_oof\", \"stack_oof\"]:\n            if name in globals():\n                try:\n                    arr = np.asarray(globals()[name])\n                    if arr.ndim == 2:\n                        return arr, f\"globals()['{name}']\"\n                except Exception:\n                    pass\n        # disk\n        for cand in [\n            \"/kaggle/working/oof.npy\",\n            \"/kaggle/working/oof_cat.npy\",\n            \"/kaggle/working/oof_logits.npy\",\n            \"/kaggle/working/oof_raw.npy\",\n        ]:\n            if os.path.exists(cand):\n                try:\n                    arr = np.load(cand)\n                    return arr, cand\n                except Exception:\n                    pass\n        return None, None\n\n    def pick_base_submit():\n        base_candidates = [\n            \"/kaggle/working/submit_patched25.parquet\",  # <- this pass should start from patched25\n            \"/kaggle/working/submit_patched20.parquet\",\n            \"/kaggle/working/submit_patched15.parquet\",\n            \"/kaggle/working/submit_patched.parquet\",\n            \"/kaggle/working/submit.parquet\",\n            \"/kaggle/working/submission.parquet\",\n        ]\n        return next((p for p in base_candidates if os.path.exists(p)), None)\n\n    def ensure_preprocessed_matrices(data_dir, target_cols):\n        \"\"\"\n        Returns X, X_test, Y, cat_features\n        1) Try globals\n        2) Else build from parquet\n        \"\"\"\n        have = all(v in globals() for v in [\"X\", \"X_test\", \"y_mat\", \"cat_features\"])\n        if have:\n            X_ = globals()[\"X\"]\n            X_test_ = globals()[\"X_test\"]\n            Y_ = np.asarray(globals()[\"y_mat\"])\n            catf_ = globals()[\"cat_features\"]\n            if Y_.shape[1] == len(target_cols):\n                print(\"Using X/X_test/y_mat/cat_features from globals().\")\n                return X_, X_test_, Y_, catf_\n            else:\n                print(\"Globals found but target dim mismatch -> rebuilding matrices...\")\n\n        print(\"Building X/X_test/y_mat/cat_features from parquet (no globals found)...\")\n        t0 = time.time()\n\n        train_main = pd.read_parquet(os.path.join(data_dir, \"train_main_features.parquet\"))\n        train_extra = pd.read_parquet(os.path.join(data_dir, \"train_extra_features.parquet\"))\n        test_main = pd.read_parquet(os.path.join(data_dir, \"test_main_features.parquet\"))\n        test_extra = pd.read_parquet(os.path.join(data_dir, \"test_extra_features.parquet\"))\n        y_df = pd.read_parquet(os.path.join(data_dir, \"train_target.parquet\"))[[\"customer_id\"] + target_cols].copy()\n\n        # merge safely by id\n        train_df = train_main.merge(train_extra, on=\"customer_id\", how=\"left\")\n        test_df = test_main.merge(test_extra, on=\"customer_id\", how=\"left\")\n        del train_main, train_extra, test_main, test_extra\n        gc.collect()\n\n        # align\n        train_df = train_df.sort_values(\"customer_id\").reset_index(drop=True)\n        test_df = test_df.sort_values(\"customer_id\").reset_index(drop=True)\n        y_df = y_df.sort_values(\"customer_id\").reset_index(drop=True)\n\n        if not np.array_equal(train_df[\"customer_id\"].values, y_df[\"customer_id\"].values):\n            train_df = train_df.merge(y_df[[\"customer_id\"]], on=\"customer_id\", how=\"inner\")\n            train_df = train_df.sort_values(\"customer_id\").reset_index(drop=True)\n            y_df = y_df.sort_values(\"customer_id\").reset_index(drop=True)\n            assert np.array_equal(train_df[\"customer_id\"].values, y_df[\"customer_id\"].values), \\\n                \"Mismatch customer_id between train features and train_target\"\n\n        Y_ = y_df[target_cols].astype(np.uint8).values\n\n        feature_cols = [c for c in train_df.columns if c != \"customer_id\"]\n        cat_cols = [c for c in feature_cols if c.startswith(\"cat_feature\")]\n        num_cols = [c for c in feature_cols if c not in cat_cols]\n\n        for c in tqdm(cat_cols, desc=\"Patch30-prep: categorical stringify\"):\n            train_df[c] = train_df[c].fillna(\"__MISSING__\").astype(str)\n            test_df[c] = test_df[c].fillna(\"__MISSING__\").astype(str)\n\n        for c in tqdm(num_cols, desc=\"Patch30-prep: numeric downcast\"):\n            train_df[c] = pd.to_numeric(train_df[c], errors=\"coerce\").astype(np.float32)\n            test_df[c] = pd.to_numeric(test_df[c], errors=\"coerce\").astype(np.float32)\n\n        X_ = train_df[feature_cols].copy()\n        X_test_ = test_df[feature_cols].copy()\n        catf_ = [feature_cols.index(c) for c in cat_cols]\n\n        print(f\"Built matrices in {(time.time()-t0)/60:.1f} min | X={X_.shape} X_test={X_test_.shape} cats={len(catf_)}\")\n        return X_, X_test_, Y_, catf_\n\n    def save_fallback_outputs(err_msg: str):\n        # report\n        pd.DataFrame([{\n            \"target\": \"__ALL__\",\n            \"pred_col\": \"__ALL__\",\n            \"pos_rate\": np.nan,\n            \"group\": \"n/a\",\n            \"mode\": \"ERROR_FALLBACK\",\n            \"base_auc_val\": np.nan,\n            \"best_auc_val\": np.nan,\n            \"gain\": np.nan,\n            \"best_w\": np.nan,\n            \"mins\": 0.0,\n            \"status\": \"ERROR_SKIP\",\n            \"reason\": str(err_msg)[:1000],\n        }]).to_csv(REPORT_PATH, index=False)\n\n        # copy base submit if possible\n        base_path = pick_base_submit()\n        if base_path is not None:\n            sub = pd.read_parquet(base_path)\n            pred_cols_local = [c for c in sub.columns if c.startswith(\"predict_\")]\n            for c in pred_cols_local:\n                sub[c] = sub[c].astype(np.float64)\n            sub.to_parquet(OUT_PATH, index=False)\n            print(f\"[FALLBACK] Saved unchanged submit -> {OUT_PATH} (from {base_path})\")\n        else:\n            print(\"[FALLBACK] Base submit not found, saved only report.\")\n\n        print(f\"[FALLBACK] Saved report -> {REPORT_PATH}\")\n\n    # ----------------------------\n    # Discover data + schema\n    # ----------------------------\n    DATA_DIR = autodiscover_data_dir()\n    sample = pd.read_parquet(os.path.join(DATA_DIR, \"sample_submit.parquet\"))\n\n    submit_cols = sample.columns.tolist()\n    pred_cols = [c for c in submit_cols if c != \"customer_id\"]\n    target_cols = [c.replace(\"predict_\", \"target_\") for c in pred_cols]\n\n    # ----------------------------\n    # Load matrices (globals or build)\n    # ----------------------------\n    X, X_test, Y, cat_features = ensure_preprocessed_matrices(DATA_DIR, target_cols)\n\n    if Y.shape[1] != len(target_cols):\n        raise ValueError(f\"Shape mismatch: y_mat has {Y.shape[1]} targets, sample_submit implies {len(target_cols)}\")\n\n    # ----------------------------\n    # OOF (optional)\n    # ----------------------------\n    OOF, OOF_SRC = load_oof_if_any()\n    HAS_OOF = isinstance(OOF, np.ndarray) and OOF.shape == Y.shape\n    if HAS_OOF:\n        print(f\"OOF found: {OOF_SRC} | shape={OOF.shape}\")\n    else:\n        OOF = None\n        print(\"OOF not found (or wrong shape) -> conservative mode (fixed weight, no gain gating).\")\n\n    # ----------------------------\n    # Base submit\n    # ----------------------------\n    BASE_SUB_PATH = pick_base_submit()\n    if BASE_SUB_PATH is None:\n        raise FileNotFoundError(\"     /kaggle/working/\")\n    base_sub = pd.read_parquet(BASE_SUB_PATH)[submit_cols].copy()\n    patched = base_sub.copy()\n    print(\"Base submit:\", BASE_SUB_PATH, patched.shape)\n\n    # ----------------------------\n    # Load targets from per_target_auc.csv\n    # ----------------------------\n    auc_df = pd.read_csv(AUC_FILE).copy()\n\n    if \"auc_rank\" not in auc_df.columns:\n        if \"auc\" in auc_df.columns:\n            auc_df = auc_df.rename(columns={\"auc\": \"auc_rank\"})\n        else:\n            raise ValueError(\" per_target_auc.csv   auc_rank/auc\")\n\n    auc_df = auc_df[auc_df[\"target\"].isin(target_cols)].copy()\n    if auc_df.empty:\n        raise ValueError(\"per_target_auc.csv    target_* \")\n\n    auc_df = auc_df.sort_values(\"auc_rank\").reset_index(drop=True)\n\n    # optional: exclude already applied in patch25\n    if EXCLUDE_ALREADY_APPLIED_FROM_PATCH25 and os.path.exists(PATCH25_REPORT_PATH):\n        rep25 = pd.read_csv(PATCH25_REPORT_PATH)\n        if \"target\" in rep25.columns and \"status\" in rep25.columns:\n            already = set(rep25.loc[rep25[\"status\"].astype(str).str.upper() == \"APPLY\", \"target\"].astype(str))\n            before_n = len(auc_df)\n            auc_df = auc_df[~auc_df[\"target\"].isin(already)].reset_index(drop=True)\n            print(f\"Excluded already applied from patch25: {before_n - len(auc_df)} targets\")\n        else:\n            print(\"patch25_report.csv exists but no target/status cols -> skip exclusion\")\n\n    targets_to_try = auc_df.head(TOP_N)[\"target\"].tolist()\n    if len(targets_to_try) == 0:\n        raise ValueError(\" targets_to_try  ( /exclude).\")\n\n    print(f\"Targets to patch (TOP-{min(TOP_N, len(targets_to_try))} worst):\")\n    print(targets_to_try)\n\n    # ----------------------------\n    # Validation split\n    # ----------------------------\n    y_sum = Y.sum(axis=1)\n    bins = pd.cut(y_sum, bins=[-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 100], labels=False).astype(int)\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_SIZE, random_state=SPLIT_SEED)\n    tr_idx, va_idx = next(sss.split(np.zeros((len(Y), 1)), bins))\n\n    X_tr = X.iloc[tr_idx]\n    X_va = X.iloc[va_idx]\n    pool_test = Pool(X_test, cat_features=cat_features)\n    print(f\"Val split: train={len(tr_idx)} val={len(va_idx)} (~{VAL_SIZE*100:.1f}%)\")\n\n    # ----------------------------\n    # Patch loop\n    # ----------------------------\n    report = []\n    applied = 0\n    skipped = 0\n\n    total_steps = len(targets_to_try) * len(PATCH_SEEDS)\n    pbar = tqdm(total=total_steps, desc=\"Patch 30 (GPU, ETA)\", mininterval=1.0)\n\n    for tname in targets_to_try:\n        j = target_cols.index(tname)\n        pred_col = tname.replace(\"target_\", \"predict_\")\n\n        row = auc_df.loc[auc_df[\"target\"] == tname].iloc[0]\n        pr = float(row[\"pos_rate\"]) if \"pos_rate\" in auc_df.columns else float(Y[:, j].mean())\n\n        # prevalence group\n        if pr < 0.005:\n            group = \"rare\"\n        elif pr < 0.05:\n            group = \"mid\"\n        else:\n            group = \"common\"\n\n        y = Y[:, j].astype(np.uint8)\n        y_tr = y[tr_idx]\n        y_va = y[va_idx]\n\n        if np.unique(y_tr).size < 2 or np.unique(y_va).size < 2:\n            skipped += 1\n            pbar.update(len(PATCH_SEEDS))\n            report.append({\n                \"target\": tname, \"pred_col\": pred_col, \"pos_rate\": pr, \"group\": group,\n                \"mode\": \"SKIP_DEGENERATE\",\n                \"base_auc_val\": np.nan, \"best_auc_val\": np.nan, \"gain\": np.nan,\n                \"best_w\": np.nan, \"mins\": 0.0, \"status\": \"SKIP_DEGENERATE\"\n            })\n            continue\n\n        # safe baseline on val only if OOF exists\n        if HAS_OOF:\n            base_val = OOF[va_idx, j].astype(np.float32)\n            base_auc = safe_auc(y_va, rank_pct_1d(base_val))\n        else:\n            base_val = None\n            base_auc = np.nan\n\n        # class weights\n        if group == \"common\":\n            spw = None\n        else:\n            pos = float(y_tr.sum())\n            neg = float(len(y_tr) - pos)\n            spw_cap = 6.0 if group == \"rare\" else 12.0\n            spw = min(neg / max(1.0, pos), spw_cap)\n\n        if hasattr(tqdm, \"write\"):\n            tqdm.write(f\"START {tname} | group={group} | pos_rate={pr:.4%} | spw={spw}\")\n\n        t0 = time.time()\n        pred_patch_val = np.zeros(len(va_idx), dtype=np.float32)\n        pred_patch_test = np.zeros(len(X_test), dtype=np.float32)\n\n        tr_pool = Pool(X_tr, label=y_tr, cat_features=cat_features)\n        va_pool = Pool(X_va, label=y_va, cat_features=cat_features)\n\n        for seed in PATCH_SEEDS:\n            model = CatBoostClassifier(**gpu_params(seed, group, spw))\n            model.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n\n            pred_patch_val += (\n                model.predict(va_pool, prediction_type=\"RawFormulaVal\").reshape(-1).astype(np.float32)\n                / len(PATCH_SEEDS)\n            )\n            pred_patch_test += (\n                model.predict(pool_test, prediction_type=\"RawFormulaVal\").reshape(-1).astype(np.float32)\n                / len(PATCH_SEEDS)\n            )\n\n            del model\n            gc.collect()\n            pbar.update(1)\n\n        del tr_pool, va_pool\n        gc.collect()\n\n        # weight selection\n        if HAS_OOF and np.isfinite(base_auc):\n            best_w, best_auc = 0.0, float(base_auc)\n            for w in W_GRID:\n                rblend = (1.0 - w) * rank_pct_1d(base_val) + w * rank_pct_1d(pred_patch_val)\n                a = safe_auc(y_va, rblend)\n                if np.isfinite(a) and a > best_auc:\n                    best_auc, best_w = float(a), float(w)\n\n            gain = float(best_auc - base_auc)\n            apply_patch = (best_w > 0) and (gain >= MIN_GAIN)\n            mode = \"OOF_TUNED\"\n        else:\n            if group == \"rare\":\n                best_w = float(FIXED_W_NO_OOF_RARE)\n            elif group == \"mid\":\n                best_w = float(FIXED_W_NO_OOF_MID)\n            else:\n                best_w = float(FIXED_W_NO_OOF_COM)\n            best_auc = safe_auc(y_va, rank_pct_1d(pred_patch_val))  # info only\n            gain = np.nan\n            apply_patch = best_w > 0\n            mode = \"NO_OOF_FIXED\"\n\n        elapsed_min = (time.time() - t0) / 60.0\n\n        if apply_patch:\n            base_scores_test = patched[pred_col].to_numpy(dtype=np.float32)\n            patched[pred_col] = rank_blend_logits(base_scores_test, pred_patch_test, w=best_w).astype(np.float64)\n            applied += 1\n            status = \"APPLY\"\n        else:\n            skipped += 1\n            status = \"SKIP_LOW_GAIN\"\n\n        if hasattr(tqdm, \"write\"):\n            tqdm.write(\n                f\"DONE  {tname} | status={status} | mode={mode} | w={best_w:.2f} | \"\n                f\"base_auc={base_auc if np.isfinite(base_auc) else np.nan:.4f} | \"\n                f\"best_auc={best_auc if np.isfinite(best_auc) else np.nan:.4f} | \"\n                f\"mins={elapsed_min:.1f}\"\n            )\n\n        report.append({\n            \"target\": tname,\n            \"pred_col\": pred_col,\n            \"pos_rate\": pr,\n            \"group\": group,\n            \"mode\": mode,\n            \"base_auc_val\": float(base_auc) if np.isfinite(base_auc) else np.nan,\n            \"best_auc_val\": float(best_auc) if np.isfinite(best_auc) else np.nan,\n            \"gain\": float(gain) if np.isfinite(gain) else np.nan,\n            \"best_w\": float(best_w),\n            \"mins\": float(elapsed_min),\n            \"status\": status,\n        })\n\n    pbar.close()\n\n    # ----------------------------\n    # Save outputs\n    # ----------------------------\n    rep_df = pd.DataFrame(report)\n    if len(rep_df):\n        status_order = {\"APPLY\": 0, \"SKIP_LOW_GAIN\": 1, \"SKIP_DEGENERATE\": 2}\n        rep_df[\"_order\"] = rep_df[\"status\"].map(status_order).fillna(99).astype(int)\n        rep_df = rep_df.sort_values([\"_order\", \"gain\"], ascending=[True, False]).drop(columns=[\"_order\"])\n\n    rep_df.to_csv(REPORT_PATH, index=False)\n\n    patched = patched[submit_cols].copy()\n    for c in pred_cols:\n        patched[c] = patched[c].astype(np.float64)   # schema safety\n    patched.to_parquet(OUT_PATH, index=False)\n\n    print(\"\\nApplied:\", applied, \"| Skipped:\", skipped)\n    print(\"Saved:\", OUT_PATH, patched.shape)\n    print(\"Saved report:\", REPORT_PATH)\n\n    if len(rep_df):\n        print(\"\\nTop applied patches:\")\n        show_cols = [c for c in [\"target\",\"group\",\"mode\",\"best_w\",\"base_auc_val\",\"best_auc_val\",\"gain\",\"mins\"] if c in rep_df.columns]\n        print(rep_df[rep_df[\"status\"] == \"APPLY\"].head(10)[show_cols].to_string(index=False))\n\nexcept Exception as e:\n    # --------------------------------------------------------\n    # SAFE fallback: don't stop notebook\n    # --------------------------------------------------------\n    err_text = f\"{type(e).__name__}: {e}\"\n    tb = traceback.format_exc()\n\n    try:\n        with open(\"/kaggle/working/patch30_error.log\", \"w\", encoding=\"utf-8\") as f:\n            f.write(tb)\n    except Exception:\n        pass\n\n    print(\"\\n[PATCH30 SAFE MODE]  ,    .\")\n    print(\"[PATCH30 SAFE MODE] :\", err_text)\n    print(\"[PATCH30 SAFE MODE]    /kaggle/working/patch30_error.log\")\n\n    try:\n        import numpy as np\n        import pandas as pd\n        pd.DataFrame([{\n            \"target\": \"__ALL__\",\n            \"pred_col\": \"__ALL__\",\n            \"pos_rate\": np.nan,\n            \"group\": \"n/a\",\n            \"mode\": \"ERROR_FALLBACK\",\n            \"base_auc_val\": np.nan,\n            \"best_auc_val\": np.nan,\n            \"gain\": np.nan,\n            \"best_w\": np.nan,\n            \"mins\": 0.0,\n            \"status\": \"ERROR_SKIP\",\n            \"reason\": err_text[:1000],\n        }]).to_csv(\"/kaggle/working/patch30_report.csv\", index=False)\n\n        base_candidates = [\n            \"/kaggle/working/submit_patched25.parquet\",\n            \"/kaggle/working/submit_patched20.parquet\",\n            \"/kaggle/working/submit_patched15.parquet\",\n            \"/kaggle/working/submit_patched.parquet\",\n            \"/kaggle/working/submit.parquet\",\n            \"/kaggle/working/submission.parquet\",\n        ]\n        base_path = next((p for p in base_candidates if os.path.exists(p)), None)\n        if base_path is not None:\n            sub = pd.read_parquet(base_path)\n            pred_cols_local = [c for c in sub.columns if c.startswith(\"predict_\")]\n            for c in pred_cols_local:\n                sub[c] = sub[c].astype(np.float64)\n            sub.to_parquet(\"/kaggle/working/submit_patched30.parquet\", index=False)\n            print(f\"[PATCH30 SAFE MODE] Saved fallback submit -> /kaggle/working/submit_patched30.parquet (from {base_path})\")\n        else:\n            print(\"[PATCH30 SAFE MODE]    ,   report.\")\n    except Exception as e2:\n        print(\"[PATCH30 SAFE MODE]    fallback outputs:\", repr(e2))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-24T18:55:19.690090Z",
     "iopub.execute_input": "2026-02-24T18:55:19.690646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Building X/X_test/y_mat/cat_features from parquet (no globals found)...\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Patch30-prep: categorical stringify:   0%|          | 0/67 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "167fdd626c7d40af83dbf099ecf1bdab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Patch30-prep: numeric downcast:   0%|          | 0/2373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0f08a8170b845f29b536d6ebcbfa893"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Built matrices in 1.0 min | X=(750000, 2440) X_test=(250000, 2440) cats=67\nOOF not found (or wrong shape) -> conservative mode (fixed weight, no gain gating).\nBase submit: /kaggle/working/submit_patched25.parquet (250000, 42)\nTargets to patch (TOP-30 worst):\n['target_9_3', 'target_9_6', 'target_3_1', 'target_5_2', 'target_6_2', 'target_6_1', 'target_3_3', 'target_2_4', 'target_5_1', 'target_10_1', 'target_9_1', 'target_6_3', 'target_9_7', 'target_2_6', 'target_2_5', 'target_1_2', 'target_7_1', 'target_7_3', 'target_2_1', 'target_2_3', 'target_9_2', 'target_1_4', 'target_4_1', 'target_7_2', 'target_9_5', 'target_1_3', 'target_8_2', 'target_2_7', 'target_6_4', 'target_8_3']\nVal split: train=712500 val=37500 (~5.0%)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Patch 30 (GPU, ETA):   0%|          | 0/90 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8649b076581449628e2d9e694b494afb"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "START target_9_3 | group=mid | pos_rate=1.8679% | spw=12.0\nDONE  target_9_3 | status=APPLY | mode=NO_OOF_FIXED | w=0.20 | base_auc=nan | best_auc=0.7194 | mins=2.3\nSTART target_9_6 | group=common | pos_rate=22.3072% | spw=None\nDONE  target_9_6 | status=APPLY | mode=NO_OOF_FIXED | w=0.15 | base_auc=nan | best_auc=0.7012 | mins=13.7\nSTART target_3_1 | group=common | pos_rate=9.8373% | spw=None\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "id": "fa10dc6d-4d1a-4e6f-a1a5-d95ee4bf8368",
   "cell_type": "code",
   "source": "!cd /kaggle/working\nFileLink(\"submit_patched30.parquet\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-24T18:39:28.483081Z",
     "iopub.execute_input": "2026-02-24T18:39:28.483295Z",
     "iopub.status.idle": "2026-02-24T18:39:29.007536Z",
     "shell.execute_reply.started": "2026-02-24T18:39:28.483281Z",
     "shell.execute_reply": "2026-02-24T18:39:29.007106Z"
    }
   },
   "outputs": [
    {
     "execution_count": 9,
     "output_type": "execute_result",
     "data": {
      "text/plain": "/kaggle/working/submit_patched25.parquet",
      "text/html": "<a href='submit_patched25.parquet' target='_blank'>submit_patched25.parquet</a><br>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 9
  },
  {
   "id": "b66fff37-1eff-4bcc-b5d0-c070bf8f9b52",
   "cell_type": "code",
   "source": "while True:\n    continue",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-24T18:39:26.441018Z",
     "iopub.status.idle": "2026-02-24T18:39:26.441161Z",
     "shell.execute_reply.started": "2026-02-24T18:39:26.441092Z",
     "shell.execute_reply": "2026-02-24T18:39:26.441100Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}